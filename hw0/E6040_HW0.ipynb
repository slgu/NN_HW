{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floatX (('float64', 'float32')) \n",
      "    Doc:  Default floating-point precision for python casts\n",
      "    Value:  float32\n",
      "\n",
      "warn_float64 (('ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  Do an action when a tensor variable with float64 dtype is created. They can't be run on the GPU with the current(old) gpu back-end and are slow with gamer GPUs.\n",
      "    Value:  ignore\n",
      "\n",
      "cast_policy (('custom', 'numpy+floatX')) \n",
      "    Doc:  Rules for implicit type casting\n",
      "    Value:  custom\n",
      "\n",
      "int_division (('int', 'raise', 'floatX')) \n",
      "    Doc:  What to do when one computes x / y, where both x and y are of integer types\n",
      "    Value:  int\n",
      "\n",
      "device (cpu, gpu*, opencl*, cuda*) \n",
      "    Doc:  Default device for computations. If gpu*, change the default to try to move computation to it and to put shared variable of float32 on it. Do not use upper case letters, only lower case even if NVIDIA use capital letters.\n",
      "    Value:  gpu\n",
      "\n",
      "gpuarray.init_device (<type 'str'>) \n",
      "    Doc:  \n",
      "             Device to initialize for gpuarray use without moving\n",
      "             computations automatically.\n",
      "             \n",
      "    Value:  \n",
      "\n",
      "init_gpu_device (('', 'gpu', 'gpu0', 'gpu1', 'gpu2', 'gpu3', 'gpu4', 'gpu5', 'gpu6', 'gpu7', 'gpu8', 'gpu9', 'gpu10', 'gpu11', 'gpu12', 'gpu13', 'gpu14', 'gpu15')) \n",
      "    Doc:  Initialize the gpu device to use, works only if device=cpu. Unlike 'device', setting this option will NOT move computations, nor shared variables, to the specified GPU. It can be used to run GPU-specific tests on a particular GPU.\n",
      "    Value:  \n",
      "\n",
      "force_device (<function booltype at 0x7f7300b731b8>) \n",
      "    Doc:  Raise an error if we can't use the specified device\n",
      "    Value:  False\n",
      "\n",
      "print_active_device (<function booltype at 0x7f7300b73320>) \n",
      "    Doc:  Print active device at when the GPU device is initialized.\n",
      "    Value:  True\n",
      "\n",
      "mode (('Mode', 'ProfileMode', 'DebugMode', 'FAST_RUN', 'FAST_COMPILE', 'PROFILE_MODE', 'DEBUG_MODE')) \n",
      "    Doc:  Default compilation mode\n",
      "    Value:  Mode\n",
      "\n",
      "cxx (<type 'str'>) \n",
      "    Doc:  The C++ compiler to use. Currently only g++ is supported, but supporting additional compilers should not be too difficult. If it is empty, no C++ code is compiled.\n",
      "    Value:  /usr/bin/g++\n",
      "\n",
      "linker (('cvm', 'c|py', 'py', 'c', 'c|py_nogc', 'vm', 'vm_nogc', 'cvm_nogc')) \n",
      "    Doc:  Default linker used if the theano flags mode is Mode or ProfileMode(deprecated)\n",
      "    Value:  cvm\n",
      "\n",
      "allow_gc (<function booltype at 0x7f7300b73938>) \n",
      "    Doc:  Do we default to delete intermediate results during Theano function calls? Doing so lowers the memory requirement, but asks that we reallocate memory at the next function call. This is implemented for the default linker, but may not work for all linkers.\n",
      "    Value:  True\n",
      "\n",
      "optimizer (('fast_run', 'merge', 'fast_compile', 'None')) \n",
      "    Doc:  Default optimizer. If not None, will use this linker with the Mode object (not ProfileMode(deprecated) or DebugMode)\n",
      "    Value:  fast_run\n",
      "\n",
      "optimizer_verbose (<function booltype at 0x7f7300b73b18>) \n",
      "    Doc:  If True, we print all optimization being applied\n",
      "    Value:  False\n",
      "\n",
      "on_opt_error (('warn', 'raise', 'pdb')) \n",
      "    Doc:  What to do when an optimization crashes: warn and skip it, raise the exception, or fall into the pdb debugger.\n",
      "    Value:  warn\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f7300b78090>\n",
      "    Doc:  This config option was removed in 0.5: do not use it!\n",
      "    Value:  True\n",
      "\n",
      "nocleanup (<function booltype at 0x7f7300b73d70>) \n",
      "    Doc:  Suppress the deletion of code files that did not compile cleanly\n",
      "    Value:  False\n",
      "\n",
      "on_unused_input (('raise', 'warn', 'ignore')) \n",
      "    Doc:  What to do if a variable in the 'inputs' list of  theano.function() is not used in the graph.\n",
      "    Value:  raise\n",
      "\n",
      "tensor.cmp_sloppy (<type 'int'>) \n",
      "    Doc:  Relax tensor._allclose (0) not at all, (1) a bit, (2) more\n",
      "    Value:  0\n",
      "\n",
      "tensor.local_elemwise_fusion (<function booltype at 0x7f7300b7a0c8>) \n",
      "    Doc:  Enable or not in fast_run mode(fast_run optimization) the elemwise fusion optimization\n",
      "    Value:  True\n",
      "\n",
      "gpu.local_elemwise_fusion (<function booltype at 0x7f7300b7a230>) \n",
      "    Doc:  Enable or not in fast_run mode(fast_run optimization) the gpu elemwise fusion optimization\n",
      "    Value:  True\n",
      "\n",
      "lib.amdlibm (<function booltype at 0x7f7300b7a398>) \n",
      "    Doc:  Use amd's amdlibm numerical library\n",
      "    Value:  False\n",
      "\n",
      "gpuelemwise.sync (<function booltype at 0x7f7300b7a500>) \n",
      "    Doc:  when true, wait that the gpu fct finished and check it error code.\n",
      "    Value:  True\n",
      "\n",
      "traceback.limit (<type 'int'>) \n",
      "    Doc:  The number of stack to trace. -1 mean all.\n",
      "    Value:  7\n",
      "\n",
      "experimental.mrg (<function booltype at 0x7f7300b7a6e0>) \n",
      "    Doc:  Another random number generator that work on the gpu\n",
      "    Value:  False\n",
      "\n",
      "experimental.unpickle_gpu_on_cpu (<function booltype at 0x7f7300b7a848>) \n",
      "    Doc:  Allow unpickling of pickled CudaNdarrays as numpy.ndarrays.This is useful, if you want to open a CudaNdarray without having cuda installed.If you have cuda installed, this will force unpickling tobe done on the cpu to numpy.ndarray.Please be aware that this may get you access to the data,however, trying to unpicke gpu functions will not succeed.This flag is experimental and may be removed any time, whengpu<>cpu transparency is solved.\n",
      "    Value:  False\n",
      "\n",
      "numpy.seterr_all (('ignore', 'warn', 'raise', 'call', 'print', 'log', 'None')) \n",
      "    Doc:  (\"Sets numpy's behaviour for floating-point errors, \", \"see numpy.seterr. 'None' means not to change numpy's default, which can be different for different numpy releases. This flag sets the default behaviour for all kinds of floating-point errors, its effect can be overriden for specific errors by the following flags: seterr_divide, seterr_over, seterr_under and seterr_invalid.\")\n",
      "    Value:  ignore\n",
      "\n",
      "numpy.seterr_divide (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for division by zero, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_over (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for floating-point overflow, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_under (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for floating-point underflow, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_invalid (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for invalid floating-point operation, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "warn.ignore_bug_before (('0.6', 'None', 'all', '0.3', '0.4', '0.4.1', '0.5', '0.7')) \n",
      "    Doc:  If 'None', we warn about all Theano bugs found by default. If 'all', we don't warn about Theano bugs found by default. If a version, we print only the warnings relative to Theano bugs found after that version. Warning for specific bugs can be configured with specific [warn] flags.\n",
      "    Value:  0.6\n",
      "\n",
      "warn.argmax_pushdown_bug (<function booltype at 0x7f7300b7ad70>) \n",
      "    Doc:  Warn if in past version of Theano we generated a bug with the theano.tensor.nnet.nnet.local_argmax_pushdown optimization. Was fixed 27 may 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.gpusum_01_011_0111_bug (<function booltype at 0x7f7300b7aed8>) \n",
      "    Doc:  Warn if we are in a case where old version of Theano had a silent bug with GpuSum pattern 01,011 and 0111 when the first dimensions was bigger then 4096. Was fixed 31 may 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.sum_sum_bug (<function booltype at 0x7f7300b7d0c8>) \n",
      "    Doc:  Warn if we are in a case where Theano version between version 9923a40c7b7a and the 2 august 2010 (fixed date), generated an error in that case. This happens when there are 2 consecutive sums in the graph, bad code was generated. Was fixed 2 August 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.sum_div_dimshuffle_bug (<function booltype at 0x7f7300b7d230>) \n",
      "    Doc:  Warn if previous versions of Theano (between rev. 3bd9b789f5e8, 2010-06-16, and cfc6322e5ad4, 2010-08-03) would have given incorrect result. This bug was triggered by sum of division of dimshuffled tensors.\n",
      "    Value:  False\n",
      "\n",
      "warn.subtensor_merge_bug (<function booltype at 0x7f7300b7d398>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.5rc2) could have given incorrect results when indexing into a subtensor with negative stride (for instance, for instance, x[a:b:-1][c]).\n",
      "    Value:  False\n",
      "\n",
      "warn.gpu_set_subtensor1 (<function booltype at 0x7f7300b7d500>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.6) could have given incorrect results when moving to the gpu set_subtensor(x[int vector], new_value)\n",
      "    Value:  False\n",
      "\n",
      "warn.vm_gc_bug (<function booltype at 0x7f7300b7d668>) \n",
      "    Doc:  There was a bug that existed in the default Theano configuration, only in the development version between July 5th 2012 and July 30th 2012. This was not in a released version. If your code was affected by this bug, a warning will be printed during the code execution if you use the `linker=vm,vm.lazy=True,warn.vm_gc_bug=True` Theano flags. This warning is disabled by default as the bug was not released.\n",
      "    Value:  False\n",
      "\n",
      "warn.signal_conv2d_interface (<function booltype at 0x7f7300b7d7d0>) \n",
      "    Doc:  Warn we use the new signal.conv2d() when its interface changed mid June 2014\n",
      "    Value:  True\n",
      "\n",
      "warn.reduce_join (<function booltype at 0x7f7300b7d938>) \n",
      "    Doc:  Your current code is fine, but Theano versions prior to 0.7 (or this development version) might have given an incorrect result. To disable this warning, set the Theano flag warn.reduce_join to False. The problem was an optimization, that modified the pattern \"Reduce{scalar.op}(Join(axis=0, a, b), axis=0)\", did not check the reduction axis. So if the reduction axis was not 0, you got a wrong answer.\n",
      "    Value:  True\n",
      "\n",
      "warn.inc_set_subtensor1 (<function booltype at 0x7f7300b7daa0>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.7) could have given incorrect results for inc_subtensor and set_subtensor when using some patterns of advanced indexing (indexing with one vector or matrix of ints).\n",
      "    Value:  True\n",
      "\n",
      "compute_test_value (('off', 'ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  If 'True', Theano will run each op at graph build time, using Constants, SharedVariables and the tag 'test_value' as inputs to the function. This helps the user track down problems in the graph before it gets optimized.\n",
      "    Value:  off\n",
      "\n",
      "compute_test_value_opt (('off', 'ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  For debugging Theano optimization only. Same as compute_test_value, but is used during Theano optimization\n",
      "    Value:  off\n",
      "\n",
      "unpickle_function (<function booltype at 0x7f7300b7dcf8>) \n",
      "    Doc:  Replace unpickled Theano functions with None. This is useful to unpickle old graphs that pickled them when it shouldn't\n",
      "    Value:  True\n",
      "\n",
      "reoptimize_unpickled_function (<function booltype at 0x7f7300b7de60>) \n",
      "    Doc:  Re-optimize the graph when a theano function is unpickled from the disk.\n",
      "    Value:  True\n",
      "\n",
      "exception_verbosity (('low', 'high')) \n",
      "    Doc:  If 'low', the text of exceptions will generally refer to apply nodes with short names such as Elemwise{add_no_inplace}. If 'high', some exceptions will also refer to apply nodes with long descriptions  like:\n",
      "        A. Elemwise{add_no_inplace}\n",
      "                B. log_likelihood_v_given_h\n",
      "                C. log_likelihood_h\n",
      "    Value:  low\n",
      "\n",
      "openmp (<function booltype at 0x7f7300b800c8>) \n",
      "    Doc:  Allow (or not) parallel computation on the CPU with OpenMP. This is the default value used when creating an Op that supports OpenMP parallelization. It is preferable to define it via the Theano configuration file ~/.theanorc or with the environment variable THEANO_FLAGS. Parallelization is only done for some operations that implement it, and even for operations that implement parallelism, each operation is free to respect this flag or not. You can control the number of threads used with the environment variable OMP_NUM_THREADS. If it is set to 1, we disable openmp in Theano by default.\n",
      "    Value:  False\n",
      "\n",
      "openmp_elemwise_minsize (<type 'int'>) \n",
      "    Doc:  If OpenMP is enabled, this is the minimum size of vectors for which the openmp parallelization is enabled in element wise ops.\n",
      "    Value:  200000\n",
      "\n",
      "check_input (<function booltype at 0x7f7300b802a8>) \n",
      "    Doc:  Specify if types should check their input in their C code. It can be used to speed up compilation, reduce overhead (particularly for scalars) and reduce the number of generated C files.\n",
      "    Value:  True\n",
      "\n",
      "cache_optimizations (<function booltype at 0x7f7300b80410>) \n",
      "    Doc:  WARNING: work in progress, does not work yet. Specify if the optimization cache should be used. This cache will any optimized graph and its optimization. Actually slow downs a lot the first optimization, and could possibly still contains some bugs. Use at your own risks.\n",
      "    Value:  False\n",
      "\n",
      "gcc.cxxflags (<type 'str'>) \n",
      "    Doc:  Extra compiler flags for gcc\n",
      "    Value:  \n",
      "\n",
      "compile.wait (<type 'int'>) \n",
      "    Doc:  Time to wait before retrying to aquire the compile lock.\n",
      "    Value:  5\n",
      "\n",
      "compile.timeout (<type 'int'>) \n",
      "    Doc:  In seconds, time that a process will wait before deciding to\n",
      "override an existing lock. An override only happens when the existing\n",
      "lock is held by the same owner *and* has not been 'refreshed' by this\n",
      "owner for more than this period. Refreshes are done every half timeout\n",
      "period for running processes.\n",
      "    Value:  120\n",
      "\n",
      "compiledir_format (<type 'str'>) \n",
      "    Doc:  Format string for platform-dependent compiled module subdirectory\n",
      "(relative to base_compiledir). Available keys: gxx_version, hostname,\n",
      "numpy_version, platform, processor, python_bitwidth,\n",
      "python_int_bitwidth, python_version, short_platform, theano_version.\n",
      "Defaults to 'compiledir_%(short_platform)s-%(processor)s-%(python_vers\n",
      "ion)s-%(python_bitwidth)s'.\n",
      "    Value:  compiledir_%(short_platform)s-%(processor)s-%(python_version)s-%(python_bitwidth)s\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f7300038a50>\n",
      "    Doc:  platform-independent root directory for compiled modules\n",
      "    Value:  /home/ubuntu/.theano\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f7300038b10>\n",
      "    Doc:  platform-dependent cache directory for compiled modules\n",
      "    Value:  /home/ubuntu/.theano/compiledir_Linux-3.13--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.11-64\n",
      "\n",
      "cmodule.mac_framework_link (<function booltype at 0x7f7300039a28>) \n",
      "    Doc:  If set to True, breaks certain MacOS installations with the infamous Bus Error\n",
      "    Value:  False\n",
      "\n",
      "cmodule.warn_no_version (<function booltype at 0x7f7300039b90>) \n",
      "    Doc:  If True, will print a warning when compiling one or more Op with C code that can't be cached because there is no c_code_cache_version() function associated to at least one of those Ops.\n",
      "    Value:  False\n",
      "\n",
      "cmodule.remove_gxx_opt (<function booltype at 0x7f7300039cf8>) \n",
      "    Doc:  If True, will remove the -O* parameter passed to g++.This is useful to debug in gdb modules compiled by Theano.The parameter -g is passed by default to g++\n",
      "    Value:  False\n",
      "\n",
      "cmodule.compilation_warning (<function booltype at 0x7f7300039e60>) \n",
      "    Doc:  If True, will print compilation warnings.\n",
      "    Value:  False\n",
      "\n",
      "cmodule.preload_cache (<function booltype at 0x7f7300042050>) \n",
      "    Doc:  If set to True, will preload the C module cache at import time\n",
      "    Value:  False\n",
      "\n",
      "metaopt.verbose (<function booltype at 0x7f72eb1238c0>) \n",
      "    Doc:  Enable verbose output for meta optimizers\n",
      "    Value:  False\n",
      "\n",
      "optdb.position_cutoff (<type 'float'>) \n",
      "    Doc:  Where to stop eariler during optimization. It represent the position of the optimizer where to stop.\n",
      "    Value:  inf\n",
      "\n",
      "optdb.max_use_ratio (<type 'float'>) \n",
      "    Doc:  A ratio that prevent infinite loop in EquilibriumOptimizer.\n",
      "    Value:  5.0\n",
      "\n",
      "profile (<function booltype at 0x7f72eb140578>) \n",
      "    Doc:  If VM should collect profile information\n",
      "    Value:  False\n",
      "\n",
      "profile_optimizer (<function booltype at 0x7f72eb1406e0>) \n",
      "    Doc:  If VM should collect optimizer profile information\n",
      "    Value:  False\n",
      "\n",
      "profile_memory (<function booltype at 0x7f72eb140848>) \n",
      "    Doc:  If VM should collect memory profile information and print it\n",
      "    Value:  False\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f72eb153950>\n",
      "    Doc:  Useful only for the vm linkers. When lazy is None, auto detect if lazy evaluation is needed and use the apropriate version. If lazy is True/False, force the version used between Loop/LoopGC and Stack.\n",
      "    Value:  None\n",
      "\n",
      "optimizer_excluding (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will remove optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "optimizer_including (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will add optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "optimizer_requiring (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will require optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "DebugMode.patience (<type 'int'>) \n",
      "    Doc:  Optimize graph this many times to detect inconsistency\n",
      "    Value:  10\n",
      "\n",
      "DebugMode.check_c (<function booltype at 0x7f72eb10c1b8>) \n",
      "    Doc:  Run C implementations where possible\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_py (<function booltype at 0x7f72eb10c320>) \n",
      "    Doc:  Run Python implementations where possible\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_finite (<function booltype at 0x7f72eb10c488>) \n",
      "    Doc:  True -> complain about NaN/Inf results\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_strides (<type 'int'>) \n",
      "    Doc:  Check that Python- and C-produced ndarrays have same strides.  On difference: (0) - ignore, (1) warn, or (2) raise error\n",
      "    Value:  1\n",
      "\n",
      "DebugMode.warn_input_not_reused (<function booltype at 0x7f72eb10c6e0>) \n",
      "    Doc:  Generate a warning when destroy_map or view_map says that an op works inplace, but the op did not reuse the input for its output.\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_preallocated_output (<type 'str'>) \n",
      "    Doc:  Test thunks with pre-allocated memory as output storage. This is a list of strings separated by \":\". Valid values are: \"initial\" (initial storage in storage map, happens with Scan),\"previous\" (previously-returned memory), \"c_contiguous\", \"f_contiguous\", \"strided\" (positive and negative strides), \"wrong_size\" (larger and smaller dimensions), and \"ALL\" (all of the above).\n",
      "    Value:  \n",
      "\n",
      "DebugMode.check_preallocated_output_ndim (<type 'int'>) \n",
      "    Doc:  When testing with \"strided\" preallocated output memory, test all combinations of strides over that number of (inner-most) dimensions. You may want to reduce that number to reduce memory or time usage, but it is advised to keep a minimum of 2.\n",
      "    Value:  4\n",
      "\n",
      "profiling.time_thunks (<function booltype at 0x7f72eae94848>) \n",
      "    Doc:  Time individual thunks when profiling\n",
      "    Value:  True\n",
      "\n",
      "profiling.n_apply (<type 'int'>) \n",
      "    Doc:  Number of Apply instances to print by default\n",
      "    Value:  20\n",
      "\n",
      "profiling.n_ops (<type 'int'>) \n",
      "    Doc:  Number of Ops to print by default\n",
      "    Value:  20\n",
      "\n",
      "profiling.output_line_width (<type 'int'>) \n",
      "    Doc:  Max line width for the profiling output\n",
      "    Value:  512\n",
      "\n",
      "profiling.min_memory_size (<type 'int'>) \n",
      "    Doc:  For the memory profile, do not print Apply nodes if the size\n",
      "             of their outputs (in bytes) is lower than this threshold\n",
      "    Value:  1024\n",
      "\n",
      "profiling.min_peak_memory (<function booltype at 0x7f72eae94d70>) \n",
      "    Doc:  The min peak memory usage of the order\n",
      "    Value:  False\n",
      "\n",
      "profiling.destination (<type 'str'>) \n",
      "    Doc:  \n",
      "             File destination of the profiling output\n",
      "             \n",
      "    Value:  stderr\n",
      "\n",
      "ProfileMode.n_apply_to_print (<type 'int'>) \n",
      "    Doc:  Number of apply instances to print by default\n",
      "    Value:  15\n",
      "\n",
      "ProfileMode.n_ops_to_print (<type 'int'>) \n",
      "    Doc:  Number of ops to print by default\n",
      "    Value:  20\n",
      "\n",
      "ProfileMode.min_memory_size (<type 'int'>) \n",
      "    Doc:  For the memory profile, do not print apply nodes if the size\n",
      " of their outputs (in bytes) is lower then this threshold\n",
      "    Value:  1024\n",
      "\n",
      "ProfileMode.profile_memory (<function booltype at 0x7f72eaeaa050>) \n",
      "    Doc:  Enable profiling of memory used by Theano functions\n",
      "    Value:  False\n",
      "\n",
      "on_shape_error (('warn', 'raise')) \n",
      "    Doc:  warn: print a warning and use the default value. raise: raise an error\n",
      "    Value:  warn\n",
      "\n",
      "tensor.insert_inplace_optimizer_validate_nb (<type 'int'>) \n",
      "    Doc:  -1: auto, if graph have less then 500 nodes 1, else 10\n",
      "    Value:  -1\n",
      "\n",
      "experimental.local_alloc_elemwise (<function booltype at 0x7f72d3e81398>) \n",
      "    Doc:  DEPRECATED: If True, enable the experimental optimization local_alloc_elemwise. Generates error if not True. Use optimizer_excluding=local_alloc_elemwise to dsiable.\n",
      "    Value:  True\n",
      "\n",
      "experimental.local_alloc_elemwise_assert (<function booltype at 0x7f72d3e81410>) \n",
      "    Doc:  When the local_alloc_elemwise is applied, add an assert to highlight shape errors.\n",
      "    Value:  True\n",
      "\n",
      "blas.ldflags (<type 'str'>) \n",
      "    Doc:  lib[s] to include for [Fortran] level-3 blas implementation\n",
      "    Value:  -L/home/ubuntu/miniconda2/envs/theano/lib -lopenblas\n",
      "\n",
      "warn.identify_1pexp_bug (<function booltype at 0x7f72ceb116e0>) \n",
      "    Doc:  Warn if Theano versions prior to 7987b51 (2011-12-18) could have yielded a wrong result due to a bug in the is_1pexp function\n",
      "    Value:  False\n",
      "\n",
      "scan.allow_gc (<function booltype at 0x7f72cc8f1500>) \n",
      "    Doc:  Allow/disallow gc inside of Scan (default: False)\n",
      "    Value:  False\n",
      "\n",
      "unittests.rseed (<type 'str'>) \n",
      "    Doc:  Seed to use for randomized unit tests. Special value 'random' means using a seed of None.\n",
      "    Value:  666\n",
      "\n",
      "nvcc.compiler_bindir (<type 'str'>) \n",
      "    Doc:  If defined, nvcc compiler driver will seek g++ and gcc in this directory\n",
      "    Value:  \n",
      "\n",
      "cuda.root (<type 'str'>) \n",
      "    Doc:  directory with bin/, lib/, include/ for cuda utilities.\n",
      "        This directory is included via -L and -rpath when linking\n",
      "        dynamically compiled modules.  If AUTO and nvcc is in the\n",
      "        path, it will use one of nvcc parent directory.  Otherwise\n",
      "        /usr/local/cuda will be used.  Leave empty to prevent extra\n",
      "        linker directives.  Default: environment variable \"CUDA_ROOT\"\n",
      "        or else \"AUTO\".\n",
      "        \n",
      "    Value:  /usr/local/cuda-7.5\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f72cc52fc50>\n",
      "    Doc:  Extra compiler flags for nvcc\n",
      "    Value:  \n",
      "\n",
      "nvcc.fastmath (<function booltype at 0x7f72cc5ae578>) \n",
      "    Doc:  \n",
      "    Value:  False\n",
      "\n",
      "pycuda.init (<function booltype at 0x7f72cc5ae848>) \n",
      "    Doc:  If True, always initialize PyCUDA when Theano want to\n",
      "           initilize the GPU.  Currently, we must always initialize\n",
      "           PyCUDA before Theano do it.  Setting this flag to True,\n",
      "           ensure that, but always import PyCUDA.  It can be done\n",
      "           manually by importing theano.misc.pycuda_init before theano\n",
      "           initialize the GPU device.\n",
      "             \n",
      "    Value:  False\n",
      "\n",
      "cublas.lib (<type 'str'>) \n",
      "    Doc:  Name of the cuda blas library for the linker.\n",
      "    Value:  cublas\n",
      "\n",
      "dnn.conv.workmem (('small', 'none', 'large')) \n",
      "    Doc:  Default value for the workmem attribute of cudnn convolutions.\n",
      "    Value:  small\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import theano;print theano.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "... training the model\n",
      "epoch 1, minibatch 83/83, validation error 12.458333 %\n",
      "     epoch 1, minibatch 83/83, test error of best model 12.375000 %\n",
      "epoch 2, minibatch 83/83, validation error 11.010417 %\n",
      "     epoch 2, minibatch 83/83, test error of best model 10.958333 %\n",
      "epoch 3, minibatch 83/83, validation error 10.312500 %\n",
      "     epoch 3, minibatch 83/83, test error of best model 10.312500 %\n",
      "epoch 4, minibatch 83/83, validation error 9.875000 %\n",
      "     epoch 4, minibatch 83/83, test error of best model 9.833333 %\n",
      "epoch 5, minibatch 83/83, validation error 9.562500 %\n",
      "     epoch 5, minibatch 83/83, test error of best model 9.479167 %\n",
      "epoch 6, minibatch 83/83, validation error 9.322917 %\n",
      "     epoch 6, minibatch 83/83, test error of best model 9.291667 %\n",
      "epoch 7, minibatch 83/83, validation error 9.187500 %\n",
      "     epoch 7, minibatch 83/83, test error of best model 9.000000 %\n",
      "epoch 8, minibatch 83/83, validation error 8.989583 %\n",
      "     epoch 8, minibatch 83/83, test error of best model 8.958333 %\n",
      "epoch 9, minibatch 83/83, validation error 8.937500 %\n",
      "     epoch 9, minibatch 83/83, test error of best model 8.812500 %\n",
      "epoch 10, minibatch 83/83, validation error 8.750000 %\n",
      "     epoch 10, minibatch 83/83, test error of best model 8.666667 %\n",
      "epoch 11, minibatch 83/83, validation error 8.666667 %\n",
      "     epoch 11, minibatch 83/83, test error of best model 8.520833 %\n",
      "epoch 12, minibatch 83/83, validation error 8.583333 %\n",
      "     epoch 12, minibatch 83/83, test error of best model 8.416667 %\n",
      "epoch 13, minibatch 83/83, validation error 8.489583 %\n",
      "     epoch 13, minibatch 83/83, test error of best model 8.291667 %\n",
      "epoch 14, minibatch 83/83, validation error 8.427083 %\n",
      "     epoch 14, minibatch 83/83, test error of best model 8.281250 %\n",
      "epoch 15, minibatch 83/83, validation error 8.354167 %\n",
      "     epoch 15, minibatch 83/83, test error of best model 8.270833 %\n",
      "epoch 16, minibatch 83/83, validation error 8.302083 %\n",
      "     epoch 16, minibatch 83/83, test error of best model 8.239583 %\n",
      "epoch 17, minibatch 83/83, validation error 8.250000 %\n",
      "     epoch 17, minibatch 83/83, test error of best model 8.177083 %\n",
      "epoch 18, minibatch 83/83, validation error 8.229167 %\n",
      "     epoch 18, minibatch 83/83, test error of best model 8.062500 %\n",
      "epoch 19, minibatch 83/83, validation error 8.260417 %\n",
      "epoch 20, minibatch 83/83, validation error 8.260417 %\n",
      "epoch 21, minibatch 83/83, validation error 8.208333 %\n",
      "     epoch 21, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 22, minibatch 83/83, validation error 8.187500 %\n",
      "     epoch 22, minibatch 83/83, test error of best model 7.927083 %\n",
      "epoch 23, minibatch 83/83, validation error 8.156250 %\n",
      "     epoch 23, minibatch 83/83, test error of best model 7.958333 %\n",
      "epoch 24, minibatch 83/83, validation error 8.114583 %\n",
      "     epoch 24, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 25, minibatch 83/83, validation error 8.093750 %\n",
      "     epoch 25, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 26, minibatch 83/83, validation error 8.104167 %\n",
      "epoch 27, minibatch 83/83, validation error 8.104167 %\n",
      "epoch 28, minibatch 83/83, validation error 8.052083 %\n",
      "     epoch 28, minibatch 83/83, test error of best model 7.843750 %\n",
      "epoch 29, minibatch 83/83, validation error 8.052083 %\n",
      "epoch 30, minibatch 83/83, validation error 8.031250 %\n",
      "     epoch 30, minibatch 83/83, test error of best model 7.843750 %\n",
      "epoch 31, minibatch 83/83, validation error 8.010417 %\n",
      "     epoch 31, minibatch 83/83, test error of best model 7.833333 %\n",
      "epoch 32, minibatch 83/83, validation error 7.979167 %\n",
      "     epoch 32, minibatch 83/83, test error of best model 7.812500 %\n",
      "epoch 33, minibatch 83/83, validation error 7.947917 %\n",
      "     epoch 33, minibatch 83/83, test error of best model 7.739583 %\n",
      "epoch 34, minibatch 83/83, validation error 7.875000 %\n",
      "     epoch 34, minibatch 83/83, test error of best model 7.729167 %\n",
      "epoch 35, minibatch 83/83, validation error 7.885417 %\n",
      "epoch 36, minibatch 83/83, validation error 7.843750 %\n",
      "     epoch 36, minibatch 83/83, test error of best model 7.697917 %\n",
      "epoch 37, minibatch 83/83, validation error 7.802083 %\n",
      "     epoch 37, minibatch 83/83, test error of best model 7.635417 %\n",
      "epoch 38, minibatch 83/83, validation error 7.812500 %\n",
      "epoch 39, minibatch 83/83, validation error 7.812500 %\n",
      "epoch 40, minibatch 83/83, validation error 7.822917 %\n",
      "epoch 41, minibatch 83/83, validation error 7.791667 %\n",
      "     epoch 41, minibatch 83/83, test error of best model 7.625000 %\n",
      "epoch 42, minibatch 83/83, validation error 7.770833 %\n",
      "     epoch 42, minibatch 83/83, test error of best model 7.614583 %\n",
      "epoch 43, minibatch 83/83, validation error 7.750000 %\n",
      "     epoch 43, minibatch 83/83, test error of best model 7.593750 %\n",
      "epoch 44, minibatch 83/83, validation error 7.739583 %\n",
      "     epoch 44, minibatch 83/83, test error of best model 7.593750 %\n",
      "epoch 45, minibatch 83/83, validation error 7.739583 %\n",
      "epoch 46, minibatch 83/83, validation error 7.739583 %\n",
      "epoch 47, minibatch 83/83, validation error 7.739583 %\n",
      "epoch 48, minibatch 83/83, validation error 7.708333 %\n",
      "     epoch 48, minibatch 83/83, test error of best model 7.583333 %\n",
      "epoch 49, minibatch 83/83, validation error 7.677083 %\n",
      "     epoch 49, minibatch 83/83, test error of best model 7.572917 %\n",
      "epoch 50, minibatch 83/83, validation error 7.677083 %\n",
      "epoch 51, minibatch 83/83, validation error 7.677083 %\n",
      "epoch 52, minibatch 83/83, validation error 7.656250 %\n",
      "     epoch 52, minibatch 83/83, test error of best model 7.541667 %\n",
      "epoch 53, minibatch 83/83, validation error 7.656250 %\n",
      "epoch 54, minibatch 83/83, validation error 7.635417 %\n",
      "     epoch 54, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 55, minibatch 83/83, validation error 7.635417 %\n",
      "epoch 56, minibatch 83/83, validation error 7.635417 %\n",
      "epoch 57, minibatch 83/83, validation error 7.604167 %\n",
      "     epoch 57, minibatch 83/83, test error of best model 7.489583 %\n",
      "epoch 58, minibatch 83/83, validation error 7.583333 %\n",
      "     epoch 58, minibatch 83/83, test error of best model 7.458333 %\n",
      "epoch 59, minibatch 83/83, validation error 7.572917 %\n",
      "     epoch 59, minibatch 83/83, test error of best model 7.468750 %\n",
      "epoch 60, minibatch 83/83, validation error 7.572917 %\n",
      "epoch 61, minibatch 83/83, validation error 7.583333 %\n",
      "epoch 62, minibatch 83/83, validation error 7.572917 %\n",
      "     epoch 62, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 63, minibatch 83/83, validation error 7.562500 %\n",
      "     epoch 63, minibatch 83/83, test error of best model 7.510417 %\n",
      "epoch 64, minibatch 83/83, validation error 7.572917 %\n",
      "epoch 65, minibatch 83/83, validation error 7.562500 %\n",
      "epoch 66, minibatch 83/83, validation error 7.552083 %\n",
      "     epoch 66, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 67, minibatch 83/83, validation error 7.552083 %\n",
      "epoch 68, minibatch 83/83, validation error 7.531250 %\n",
      "     epoch 68, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 69, minibatch 83/83, validation error 7.531250 %\n",
      "epoch 70, minibatch 83/83, validation error 7.510417 %\n",
      "     epoch 70, minibatch 83/83, test error of best model 7.500000 %\n",
      "epoch 71, minibatch 83/83, validation error 7.520833 %\n",
      "epoch 72, minibatch 83/83, validation error 7.510417 %\n",
      "epoch 73, minibatch 83/83, validation error 7.500000 %\n",
      "     epoch 73, minibatch 83/83, test error of best model 7.489583 %\n",
      "Optimization complete with best validation score of 7.500000 %,with test performance 7.489583 %\n",
      "The code run for 74 epochs, with 9.335361 epochs/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file logistic_sgd.py ran for 7.9s\n"
     ]
    }
   ],
   "source": [
    "%run logistic_sgd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "... training\n",
      "training @ iter =  0\n",
      "epoch 1, minibatch 100/100, validation error 9.230000 %\n",
      "     epoch 1, minibatch 100/100, test error of best model 9.540000 %\n",
      "training @ iter =  100\n",
      "epoch 2, minibatch 100/100, validation error 6.170000 %\n",
      "     epoch 2, minibatch 100/100, test error of best model 6.480000 %\n",
      "training @ iter =  200\n",
      "epoch 3, minibatch 100/100, validation error 4.640000 %\n",
      "     epoch 3, minibatch 100/100, test error of best model 4.840000 %\n",
      "training @ iter =  300\n",
      "epoch 4, minibatch 100/100, validation error 3.500000 %\n",
      "     epoch 4, minibatch 100/100, test error of best model 3.930000 %\n",
      "training @ iter =  400\n",
      "epoch 5, minibatch 100/100, validation error 3.020000 %\n",
      "     epoch 5, minibatch 100/100, test error of best model 3.270000 %\n",
      "training @ iter =  500\n",
      "epoch 6, minibatch 100/100, validation error 2.820000 %\n",
      "     epoch 6, minibatch 100/100, test error of best model 2.810000 %\n",
      "training @ iter =  600\n",
      "epoch 7, minibatch 100/100, validation error 2.490000 %\n",
      "     epoch 7, minibatch 100/100, test error of best model 2.490000 %\n",
      "training @ iter =  700\n",
      "epoch 8, minibatch 100/100, validation error 2.290000 %\n",
      "     epoch 8, minibatch 100/100, test error of best model 2.210000 %\n",
      "training @ iter =  800\n",
      "epoch 9, minibatch 100/100, validation error 2.150000 %\n",
      "     epoch 9, minibatch 100/100, test error of best model 2.010000 %\n",
      "training @ iter =  900\n",
      "epoch 10, minibatch 100/100, validation error 1.990000 %\n",
      "     epoch 10, minibatch 100/100, test error of best model 1.910000 %\n",
      "training @ iter =  1000\n",
      "epoch 11, minibatch 100/100, validation error 1.850000 %\n",
      "     epoch 11, minibatch 100/100, test error of best model 1.800000 %\n",
      "training @ iter =  1100\n",
      "epoch 12, minibatch 100/100, validation error 1.790000 %\n",
      "     epoch 12, minibatch 100/100, test error of best model 1.660000 %\n",
      "training @ iter =  1200\n",
      "epoch 13, minibatch 100/100, validation error 1.770000 %\n",
      "     epoch 13, minibatch 100/100, test error of best model 1.580000 %\n",
      "training @ iter =  1300\n",
      "epoch 14, minibatch 100/100, validation error 1.740000 %\n",
      "     epoch 14, minibatch 100/100, test error of best model 1.540000 %\n",
      "training @ iter =  1400\n",
      "epoch 15, minibatch 100/100, validation error 1.680000 %\n",
      "     epoch 15, minibatch 100/100, test error of best model 1.490000 %\n",
      "training @ iter =  1500\n",
      "epoch 16, minibatch 100/100, validation error 1.620000 %\n",
      "     epoch 16, minibatch 100/100, test error of best model 1.430000 %\n",
      "training @ iter =  1600\n",
      "epoch 17, minibatch 100/100, validation error 1.580000 %\n",
      "     epoch 17, minibatch 100/100, test error of best model 1.420000 %\n",
      "training @ iter =  1700\n",
      "epoch 18, minibatch 100/100, validation error 1.560000 %\n",
      "     epoch 18, minibatch 100/100, test error of best model 1.400000 %\n",
      "training @ iter =  1800\n",
      "epoch 19, minibatch 100/100, validation error 1.550000 %\n",
      "     epoch 19, minibatch 100/100, test error of best model 1.370000 %\n",
      "training @ iter =  1900\n",
      "epoch 20, minibatch 100/100, validation error 1.520000 %\n",
      "     epoch 20, minibatch 100/100, test error of best model 1.300000 %\n",
      "training @ iter =  2000\n",
      "epoch 21, minibatch 100/100, validation error 1.500000 %\n",
      "     epoch 21, minibatch 100/100, test error of best model 1.280000 %\n",
      "training @ iter =  2100\n",
      "epoch 22, minibatch 100/100, validation error 1.460000 %\n",
      "     epoch 22, minibatch 100/100, test error of best model 1.260000 %\n",
      "training @ iter =  2200\n",
      "epoch 23, minibatch 100/100, validation error 1.430000 %\n",
      "     epoch 23, minibatch 100/100, test error of best model 1.250000 %\n",
      "training @ iter =  2300\n",
      "epoch 24, minibatch 100/100, validation error 1.390000 %\n",
      "     epoch 24, minibatch 100/100, test error of best model 1.220000 %\n",
      "training @ iter =  2400\n",
      "epoch 25, minibatch 100/100, validation error 1.370000 %\n",
      "     epoch 25, minibatch 100/100, test error of best model 1.180000 %\n",
      "training @ iter =  2500\n",
      "epoch 26, minibatch 100/100, validation error 1.350000 %\n",
      "     epoch 26, minibatch 100/100, test error of best model 1.170000 %\n",
      "training @ iter =  2600\n",
      "epoch 27, minibatch 100/100, validation error 1.330000 %\n",
      "     epoch 27, minibatch 100/100, test error of best model 1.150000 %\n",
      "training @ iter =  2700\n",
      "epoch 28, minibatch 100/100, validation error 1.300000 %"
     ]
    }
   ],
   "source": [
    "%run convolutional_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floatX (('float64', 'float32')) \n",
      "    Doc:  Default floating-point precision for python casts\n",
      "    Value:  float32\n",
      "\n",
      "warn_float64 (('ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  Do an action when a tensor variable with float64 dtype is created. They can't be run on the GPU with the current(old) gpu back-end and are slow with gamer GPUs.\n",
      "    Value:  ignore\n",
      "\n",
      "cast_policy (('custom', 'numpy+floatX')) \n",
      "    Doc:  Rules for implicit type casting\n",
      "    Value:  custom\n",
      "\n",
      "int_division (('int', 'raise', 'floatX')) \n",
      "    Doc:  What to do when one computes x / y, where both x and y are of integer types\n",
      "    Value:  int\n",
      "\n",
      "device (cpu, gpu*, opencl*, cuda*) \n",
      "    Doc:  Default device for computations. If gpu*, change the default to try to move computation to it and to put shared variable of float32 on it. Do not use upper case letters, only lower case even if NVIDIA use capital letters.\n",
      "    Value:  gpu\n",
      "\n",
      "gpuarray.init_device (<type 'str'>) \n",
      "    Doc:  \n",
      "             Device to initialize for gpuarray use without moving\n",
      "             computations automatically.\n",
      "             \n",
      "    Value:  \n",
      "\n",
      "init_gpu_device (('', 'gpu', 'gpu0', 'gpu1', 'gpu2', 'gpu3', 'gpu4', 'gpu5', 'gpu6', 'gpu7', 'gpu8', 'gpu9', 'gpu10', 'gpu11', 'gpu12', 'gpu13', 'gpu14', 'gpu15')) \n",
      "    Doc:  Initialize the gpu device to use, works only if device=cpu. Unlike 'device', setting this option will NOT move computations, nor shared variables, to the specified GPU. It can be used to run GPU-specific tests on a particular GPU.\n",
      "    Value:  \n",
      "\n",
      "force_device (<function booltype at 0x7f7300b731b8>) \n",
      "    Doc:  Raise an error if we can't use the specified device\n",
      "    Value:  False\n",
      "\n",
      "print_active_device (<function booltype at 0x7f7300b73320>) \n",
      "    Doc:  Print active device at when the GPU device is initialized.\n",
      "    Value:  True\n",
      "\n",
      "mode (('Mode', 'ProfileMode', 'DebugMode', 'FAST_RUN', 'FAST_COMPILE', 'PROFILE_MODE', 'DEBUG_MODE')) \n",
      "    Doc:  Default compilation mode\n",
      "    Value:  Mode\n",
      "\n",
      "cxx (<type 'str'>) \n",
      "    Doc:  The C++ compiler to use. Currently only g++ is supported, but supporting additional compilers should not be too difficult. If it is empty, no C++ code is compiled.\n",
      "    Value:  /usr/bin/g++\n",
      "\n",
      "linker (('cvm', 'c|py', 'py', 'c', 'c|py_nogc', 'vm', 'vm_nogc', 'cvm_nogc')) \n",
      "    Doc:  Default linker used if the theano flags mode is Mode or ProfileMode(deprecated)\n",
      "    Value:  cvm\n",
      "\n",
      "allow_gc (<function booltype at 0x7f7300b73938>) \n",
      "    Doc:  Do we default to delete intermediate results during Theano function calls? Doing so lowers the memory requirement, but asks that we reallocate memory at the next function call. This is implemented for the default linker, but may not work for all linkers.\n",
      "    Value:  True\n",
      "\n",
      "optimizer (('fast_run', 'merge', 'fast_compile', 'None')) \n",
      "    Doc:  Default optimizer. If not None, will use this linker with the Mode object (not ProfileMode(deprecated) or DebugMode)\n",
      "    Value:  fast_run\n",
      "\n",
      "optimizer_verbose (<function booltype at 0x7f7300b73b18>) \n",
      "    Doc:  If True, we print all optimization being applied\n",
      "    Value:  False\n",
      "\n",
      "on_opt_error (('warn', 'raise', 'pdb')) \n",
      "    Doc:  What to do when an optimization crashes: warn and skip it, raise the exception, or fall into the pdb debugger.\n",
      "    Value:  warn\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f7300b78090>\n",
      "    Doc:  This config option was removed in 0.5: do not use it!\n",
      "    Value:  True\n",
      "\n",
      "nocleanup (<function booltype at 0x7f7300b73d70>) \n",
      "    Doc:  Suppress the deletion of code files that did not compile cleanly\n",
      "    Value:  False\n",
      "\n",
      "on_unused_input (('raise', 'warn', 'ignore')) \n",
      "    Doc:  What to do if a variable in the 'inputs' list of  theano.function() is not used in the graph.\n",
      "    Value:  raise\n",
      "\n",
      "tensor.cmp_sloppy (<type 'int'>) \n",
      "    Doc:  Relax tensor._allclose (0) not at all, (1) a bit, (2) more\n",
      "    Value:  0\n",
      "\n",
      "tensor.local_elemwise_fusion (<function booltype at 0x7f7300b7a0c8>) \n",
      "    Doc:  Enable or not in fast_run mode(fast_run optimization) the elemwise fusion optimization\n",
      "    Value:  True\n",
      "\n",
      "gpu.local_elemwise_fusion (<function booltype at 0x7f7300b7a230>) \n",
      "    Doc:  Enable or not in fast_run mode(fast_run optimization) the gpu elemwise fusion optimization\n",
      "    Value:  True\n",
      "\n",
      "lib.amdlibm (<function booltype at 0x7f7300b7a398>) \n",
      "    Doc:  Use amd's amdlibm numerical library\n",
      "    Value:  False\n",
      "\n",
      "gpuelemwise.sync (<function booltype at 0x7f7300b7a500>) \n",
      "    Doc:  when true, wait that the gpu fct finished and check it error code.\n",
      "    Value:  True\n",
      "\n",
      "traceback.limit (<type 'int'>) \n",
      "    Doc:  The number of stack to trace. -1 mean all.\n",
      "    Value:  7\n",
      "\n",
      "experimental.mrg (<function booltype at 0x7f7300b7a6e0>) \n",
      "    Doc:  Another random number generator that work on the gpu\n",
      "    Value:  False\n",
      "\n",
      "experimental.unpickle_gpu_on_cpu (<function booltype at 0x7f7300b7a848>) \n",
      "    Doc:  Allow unpickling of pickled CudaNdarrays as numpy.ndarrays.This is useful, if you want to open a CudaNdarray without having cuda installed.If you have cuda installed, this will force unpickling tobe done on the cpu to numpy.ndarray.Please be aware that this may get you access to the data,however, trying to unpicke gpu functions will not succeed.This flag is experimental and may be removed any time, whengpu<>cpu transparency is solved.\n",
      "    Value:  False\n",
      "\n",
      "numpy.seterr_all (('ignore', 'warn', 'raise', 'call', 'print', 'log', 'None')) \n",
      "    Doc:  (\"Sets numpy's behaviour for floating-point errors, \", \"see numpy.seterr. 'None' means not to change numpy's default, which can be different for different numpy releases. This flag sets the default behaviour for all kinds of floating-point errors, its effect can be overriden for specific errors by the following flags: seterr_divide, seterr_over, seterr_under and seterr_invalid.\")\n",
      "    Value:  ignore\n",
      "\n",
      "numpy.seterr_divide (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for division by zero, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_over (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for floating-point overflow, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_under (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for floating-point underflow, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_invalid (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for invalid floating-point operation, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "warn.ignore_bug_before (('0.6', 'None', 'all', '0.3', '0.4', '0.4.1', '0.5', '0.7')) \n",
      "    Doc:  If 'None', we warn about all Theano bugs found by default. If 'all', we don't warn about Theano bugs found by default. If a version, we print only the warnings relative to Theano bugs found after that version. Warning for specific bugs can be configured with specific [warn] flags.\n",
      "    Value:  0.6\n",
      "\n",
      "warn.argmax_pushdown_bug (<function booltype at 0x7f7300b7ad70>) \n",
      "    Doc:  Warn if in past version of Theano we generated a bug with the theano.tensor.nnet.nnet.local_argmax_pushdown optimization. Was fixed 27 may 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.gpusum_01_011_0111_bug (<function booltype at 0x7f7300b7aed8>) \n",
      "    Doc:  Warn if we are in a case where old version of Theano had a silent bug with GpuSum pattern 01,011 and 0111 when the first dimensions was bigger then 4096. Was fixed 31 may 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.sum_sum_bug (<function booltype at 0x7f7300b7d0c8>) \n",
      "    Doc:  Warn if we are in a case where Theano version between version 9923a40c7b7a and the 2 august 2010 (fixed date), generated an error in that case. This happens when there are 2 consecutive sums in the graph, bad code was generated. Was fixed 2 August 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.sum_div_dimshuffle_bug (<function booltype at 0x7f7300b7d230>) \n",
      "    Doc:  Warn if previous versions of Theano (between rev. 3bd9b789f5e8, 2010-06-16, and cfc6322e5ad4, 2010-08-03) would have given incorrect result. This bug was triggered by sum of division of dimshuffled tensors.\n",
      "    Value:  False\n",
      "\n",
      "warn.subtensor_merge_bug (<function booltype at 0x7f7300b7d398>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.5rc2) could have given incorrect results when indexing into a subtensor with negative stride (for instance, for instance, x[a:b:-1][c]).\n",
      "    Value:  False\n",
      "\n",
      "warn.gpu_set_subtensor1 (<function booltype at 0x7f7300b7d500>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.6) could have given incorrect results when moving to the gpu set_subtensor(x[int vector], new_value)\n",
      "    Value:  False\n",
      "\n",
      "warn.vm_gc_bug (<function booltype at 0x7f7300b7d668>) \n",
      "    Doc:  There was a bug that existed in the default Theano configuration, only in the development version between July 5th 2012 and July 30th 2012. This was not in a released version. If your code was affected by this bug, a warning will be printed during the code execution if you use the `linker=vm,vm.lazy=True,warn.vm_gc_bug=True` Theano flags. This warning is disabled by default as the bug was not released.\n",
      "    Value:  False\n",
      "\n",
      "warn.signal_conv2d_interface (<function booltype at 0x7f7300b7d7d0>) \n",
      "    Doc:  Warn we use the new signal.conv2d() when its interface changed mid June 2014\n",
      "    Value:  True\n",
      "\n",
      "warn.reduce_join (<function booltype at 0x7f7300b7d938>) \n",
      "    Doc:  Your current code is fine, but Theano versions prior to 0.7 (or this development version) might have given an incorrect result. To disable this warning, set the Theano flag warn.reduce_join to False. The problem was an optimization, that modified the pattern \"Reduce{scalar.op}(Join(axis=0, a, b), axis=0)\", did not check the reduction axis. So if the reduction axis was not 0, you got a wrong answer.\n",
      "    Value:  True\n",
      "\n",
      "warn.inc_set_subtensor1 (<function booltype at 0x7f7300b7daa0>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.7) could have given incorrect results for inc_subtensor and set_subtensor when using some patterns of advanced indexing (indexing with one vector or matrix of ints).\n",
      "    Value:  True\n",
      "\n",
      "compute_test_value (('off', 'ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  If 'True', Theano will run each op at graph build time, using Constants, SharedVariables and the tag 'test_value' as inputs to the function. This helps the user track down problems in the graph before it gets optimized.\n",
      "    Value:  off\n",
      "\n",
      "compute_test_value_opt (('off', 'ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  For debugging Theano optimization only. Same as compute_test_value, but is used during Theano optimization\n",
      "    Value:  off\n",
      "\n",
      "unpickle_function (<function booltype at 0x7f7300b7dcf8>) \n",
      "    Doc:  Replace unpickled Theano functions with None. This is useful to unpickle old graphs that pickled them when it shouldn't\n",
      "    Value:  True\n",
      "\n",
      "reoptimize_unpickled_function (<function booltype at 0x7f7300b7de60>) \n",
      "    Doc:  Re-optimize the graph when a theano function is unpickled from the disk.\n",
      "    Value:  True\n",
      "\n",
      "exception_verbosity (('low', 'high')) \n",
      "    Doc:  If 'low', the text of exceptions will generally refer to apply nodes with short names such as Elemwise{add_no_inplace}. If 'high', some exceptions will also refer to apply nodes with long descriptions  like:\n",
      "        A. Elemwise{add_no_inplace}\n",
      "                B. log_likelihood_v_given_h\n",
      "                C. log_likelihood_h\n",
      "    Value:  low\n",
      "\n",
      "openmp (<function booltype at 0x7f7300b800c8>) \n",
      "    Doc:  Allow (or not) parallel computation on the CPU with OpenMP. This is the default value used when creating an Op that supports OpenMP parallelization. It is preferable to define it via the Theano configuration file ~/.theanorc or with the environment variable THEANO_FLAGS. Parallelization is only done for some operations that implement it, and even for operations that implement parallelism, each operation is free to respect this flag or not. You can control the number of threads used with the environment variable OMP_NUM_THREADS. If it is set to 1, we disable openmp in Theano by default.\n",
      "    Value:  False\n",
      "\n",
      "openmp_elemwise_minsize (<type 'int'>) \n",
      "    Doc:  If OpenMP is enabled, this is the minimum size of vectors for which the openmp parallelization is enabled in element wise ops.\n",
      "    Value:  200000\n",
      "\n",
      "check_input (<function booltype at 0x7f7300b802a8>) \n",
      "    Doc:  Specify if types should check their input in their C code. It can be used to speed up compilation, reduce overhead (particularly for scalars) and reduce the number of generated C files.\n",
      "    Value:  True\n",
      "\n",
      "cache_optimizations (<function booltype at 0x7f7300b80410>) \n",
      "    Doc:  WARNING: work in progress, does not work yet. Specify if the optimization cache should be used. This cache will any optimized graph and its optimization. Actually slow downs a lot the first optimization, and could possibly still contains some bugs. Use at your own risks.\n",
      "    Value:  False\n",
      "\n",
      "gcc.cxxflags (<type 'str'>) \n",
      "    Doc:  Extra compiler flags for gcc\n",
      "    Value:  \n",
      "\n",
      "compile.wait (<type 'int'>) \n",
      "    Doc:  Time to wait before retrying to aquire the compile lock.\n",
      "    Value:  5\n",
      "\n",
      "compile.timeout (<type 'int'>) \n",
      "    Doc:  In seconds, time that a process will wait before deciding to\n",
      "override an existing lock. An override only happens when the existing\n",
      "lock is held by the same owner *and* has not been 'refreshed' by this\n",
      "owner for more than this period. Refreshes are done every half timeout\n",
      "period for running processes.\n",
      "    Value:  120\n",
      "\n",
      "compiledir_format (<type 'str'>) \n",
      "    Doc:  Format string for platform-dependent compiled module subdirectory\n",
      "(relative to base_compiledir). Available keys: gxx_version, hostname,\n",
      "numpy_version, platform, processor, python_bitwidth,\n",
      "python_int_bitwidth, python_version, short_platform, theano_version.\n",
      "Defaults to 'compiledir_%(short_platform)s-%(processor)s-%(python_vers\n",
      "ion)s-%(python_bitwidth)s'.\n",
      "    Value:  compiledir_%(short_platform)s-%(processor)s-%(python_version)s-%(python_bitwidth)s\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f7300038a50>\n",
      "    Doc:  platform-independent root directory for compiled modules\n",
      "    Value:  /home/ubuntu/.theano\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f7300038b10>\n",
      "    Doc:  platform-dependent cache directory for compiled modules\n",
      "    Value:  /home/ubuntu/.theano/compiledir_Linux-3.13--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.11-64\n",
      "\n",
      "cmodule.mac_framework_link (<function booltype at 0x7f7300039a28>) \n",
      "    Doc:  If set to True, breaks certain MacOS installations with the infamous Bus Error\n",
      "    Value:  False\n",
      "\n",
      "cmodule.warn_no_version (<function booltype at 0x7f7300039b90>) \n",
      "    Doc:  If True, will print a warning when compiling one or more Op with C code that can't be cached because there is no c_code_cache_version() function associated to at least one of those Ops.\n",
      "    Value:  False\n",
      "\n",
      "cmodule.remove_gxx_opt (<function booltype at 0x7f7300039cf8>) \n",
      "    Doc:  If True, will remove the -O* parameter passed to g++.This is useful to debug in gdb modules compiled by Theano.The parameter -g is passed by default to g++\n",
      "    Value:  False\n",
      "\n",
      "cmodule.compilation_warning (<function booltype at 0x7f7300039e60>) \n",
      "    Doc:  If True, will print compilation warnings.\n",
      "    Value:  False\n",
      "\n",
      "cmodule.preload_cache (<function booltype at 0x7f7300042050>) \n",
      "    Doc:  If set to True, will preload the C module cache at import time\n",
      "    Value:  False\n",
      "\n",
      "metaopt.verbose (<function booltype at 0x7f72eb1238c0>) \n",
      "    Doc:  Enable verbose output for meta optimizers\n",
      "    Value:  False\n",
      "\n",
      "optdb.position_cutoff (<type 'float'>) \n",
      "    Doc:  Where to stop eariler during optimization. It represent the position of the optimizer where to stop.\n",
      "    Value:  inf\n",
      "\n",
      "optdb.max_use_ratio (<type 'float'>) \n",
      "    Doc:  A ratio that prevent infinite loop in EquilibriumOptimizer.\n",
      "    Value:  5.0\n",
      "\n",
      "profile (<function booltype at 0x7f72eb140578>) \n",
      "    Doc:  If VM should collect profile information\n",
      "    Value:  False\n",
      "\n",
      "profile_optimizer (<function booltype at 0x7f72eb1406e0>) \n",
      "    Doc:  If VM should collect optimizer profile information\n",
      "    Value:  False\n",
      "\n",
      "profile_memory (<function booltype at 0x7f72eb140848>) \n",
      "    Doc:  If VM should collect memory profile information and print it\n",
      "    Value:  False\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f72eb153950>\n",
      "    Doc:  Useful only for the vm linkers. When lazy is None, auto detect if lazy evaluation is needed and use the apropriate version. If lazy is True/False, force the version used between Loop/LoopGC and Stack.\n",
      "    Value:  None\n",
      "\n",
      "optimizer_excluding (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will remove optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "optimizer_including (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will add optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "optimizer_requiring (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will require optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "DebugMode.patience (<type 'int'>) \n",
      "    Doc:  Optimize graph this many times to detect inconsistency\n",
      "    Value:  10\n",
      "\n",
      "DebugMode.check_c (<function booltype at 0x7f72eb10c1b8>) \n",
      "    Doc:  Run C implementations where possible\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_py (<function booltype at 0x7f72eb10c320>) \n",
      "    Doc:  Run Python implementations where possible\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_finite (<function booltype at 0x7f72eb10c488>) \n",
      "    Doc:  True -> complain about NaN/Inf results\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_strides (<type 'int'>) \n",
      "    Doc:  Check that Python- and C-produced ndarrays have same strides.  On difference: (0) - ignore, (1) warn, or (2) raise error\n",
      "    Value:  1\n",
      "\n",
      "DebugMode.warn_input_not_reused (<function booltype at 0x7f72eb10c6e0>) \n",
      "    Doc:  Generate a warning when destroy_map or view_map says that an op works inplace, but the op did not reuse the input for its output.\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_preallocated_output (<type 'str'>) \n",
      "    Doc:  Test thunks with pre-allocated memory as output storage. This is a list of strings separated by \":\". Valid values are: \"initial\" (initial storage in storage map, happens with Scan),\"previous\" (previously-returned memory), \"c_contiguous\", \"f_contiguous\", \"strided\" (positive and negative strides), \"wrong_size\" (larger and smaller dimensions), and \"ALL\" (all of the above).\n",
      "    Value:  \n",
      "\n",
      "DebugMode.check_preallocated_output_ndim (<type 'int'>) \n",
      "    Doc:  When testing with \"strided\" preallocated output memory, test all combinations of strides over that number of (inner-most) dimensions. You may want to reduce that number to reduce memory or time usage, but it is advised to keep a minimum of 2.\n",
      "    Value:  4\n",
      "\n",
      "profiling.time_thunks (<function booltype at 0x7f72eae94848>) \n",
      "    Doc:  Time individual thunks when profiling\n",
      "    Value:  True\n",
      "\n",
      "profiling.n_apply (<type 'int'>) \n",
      "    Doc:  Number of Apply instances to print by default\n",
      "    Value:  20\n",
      "\n",
      "profiling.n_ops (<type 'int'>) \n",
      "    Doc:  Number of Ops to print by default\n",
      "    Value:  20\n",
      "\n",
      "profiling.output_line_width (<type 'int'>) \n",
      "    Doc:  Max line width for the profiling output\n",
      "    Value:  512\n",
      "\n",
      "profiling.min_memory_size (<type 'int'>) \n",
      "    Doc:  For the memory profile, do not print Apply nodes if the size\n",
      "             of their outputs (in bytes) is lower than this threshold\n",
      "    Value:  1024\n",
      "\n",
      "profiling.min_peak_memory (<function booltype at 0x7f72eae94d70>) \n",
      "    Doc:  The min peak memory usage of the order\n",
      "    Value:  False\n",
      "\n",
      "profiling.destination (<type 'str'>) \n",
      "    Doc:  \n",
      "             File destination of the profiling output\n",
      "             \n",
      "    Value:  stderr\n",
      "\n",
      "ProfileMode.n_apply_to_print (<type 'int'>) \n",
      "    Doc:  Number of apply instances to print by default\n",
      "    Value:  15\n",
      "\n",
      "ProfileMode.n_ops_to_print (<type 'int'>) \n",
      "    Doc:  Number of ops to print by default\n",
      "    Value:  20\n",
      "\n",
      "ProfileMode.min_memory_size (<type 'int'>) \n",
      "    Doc:  For the memory profile, do not print apply nodes if the size\n",
      " of their outputs (in bytes) is lower then this threshold\n",
      "    Value:  1024\n",
      "\n",
      "ProfileMode.profile_memory (<function booltype at 0x7f72eaeaa050>) \n",
      "    Doc:  Enable profiling of memory used by Theano functions\n",
      "    Value:  False\n",
      "\n",
      "on_shape_error (('warn', 'raise')) \n",
      "    Doc:  warn: print a warning and use the default value. raise: raise an error\n",
      "    Value:  warn\n",
      "\n",
      "tensor.insert_inplace_optimizer_validate_nb (<type 'int'>) \n",
      "    Doc:  -1: auto, if graph have less then 500 nodes 1, else 10\n",
      "    Value:  -1\n",
      "\n",
      "experimental.local_alloc_elemwise (<function booltype at 0x7f72d3e81398>) \n",
      "    Doc:  DEPRECATED: If True, enable the experimental optimization local_alloc_elemwise. Generates error if not True. Use optimizer_excluding=local_alloc_elemwise to dsiable.\n",
      "    Value:  True\n",
      "\n",
      "experimental.local_alloc_elemwise_assert (<function booltype at 0x7f72d3e81410>) \n",
      "    Doc:  When the local_alloc_elemwise is applied, add an assert to highlight shape errors.\n",
      "    Value:  True\n",
      "\n",
      "blas.ldflags (<type 'str'>) \n",
      "    Doc:  lib[s] to include for [Fortran] level-3 blas implementation\n",
      "    Value:  -L/home/ubuntu/miniconda2/envs/theano/lib -lopenblas\n",
      "\n",
      "warn.identify_1pexp_bug (<function booltype at 0x7f72ceb116e0>) \n",
      "    Doc:  Warn if Theano versions prior to 7987b51 (2011-12-18) could have yielded a wrong result due to a bug in the is_1pexp function\n",
      "    Value:  False\n",
      "\n",
      "scan.allow_gc (<function booltype at 0x7f72cc8f1500>) \n",
      "    Doc:  Allow/disallow gc inside of Scan (default: False)\n",
      "    Value:  False\n",
      "\n",
      "unittests.rseed (<type 'str'>) \n",
      "    Doc:  Seed to use for randomized unit tests. Special value 'random' means using a seed of None.\n",
      "    Value:  666\n",
      "\n",
      "nvcc.compiler_bindir (<type 'str'>) \n",
      "    Doc:  If defined, nvcc compiler driver will seek g++ and gcc in this directory\n",
      "    Value:  \n",
      "\n",
      "cuda.root (<type 'str'>) \n",
      "    Doc:  directory with bin/, lib/, include/ for cuda utilities.\n",
      "        This directory is included via -L and -rpath when linking\n",
      "        dynamically compiled modules.  If AUTO and nvcc is in the\n",
      "        path, it will use one of nvcc parent directory.  Otherwise\n",
      "        /usr/local/cuda will be used.  Leave empty to prevent extra\n",
      "        linker directives.  Default: environment variable \"CUDA_ROOT\"\n",
      "        or else \"AUTO\".\n",
      "        \n",
      "    Value:  /usr/local/cuda-7.5\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7f72cc52fc50>\n",
      "    Doc:  Extra compiler flags for nvcc\n",
      "    Value:  \n",
      "\n",
      "nvcc.fastmath (<function booltype at 0x7f72cc5ae578>) \n",
      "    Doc:  \n",
      "    Value:  False\n",
      "\n",
      "pycuda.init (<function booltype at 0x7f72cc5ae848>) \n",
      "    Doc:  If True, always initialize PyCUDA when Theano want to\n",
      "           initilize the GPU.  Currently, we must always initialize\n",
      "           PyCUDA before Theano do it.  Setting this flag to True,\n",
      "           ensure that, but always import PyCUDA.  It can be done\n",
      "           manually by importing theano.misc.pycuda_init before theano\n",
      "           initialize the GPU device.\n",
      "             \n",
      "    Value:  False\n",
      "\n",
      "cublas.lib (<type 'str'>) \n",
      "    Doc:  Name of the cuda blas library for the linker.\n",
      "    Value:  cublas\n",
      "\n",
      "dnn.conv.workmem (('small', 'none', 'large')) \n",
      "    Doc:  Default value for the workmem attribute of cudnn convolutions.\n",
      "    Value:  small\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import theano;print theano.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "... training\n",
      "training @ iter =  0\n",
      "epoch 1, minibatch 100/100, validation error 9.230000 %\n",
      "     epoch 1, minibatch 100/100, test error of best model 9.550000 %\n",
      "training @ iter =  100\n",
      "epoch 2, minibatch 100/100, validation error 6.170000 %\n",
      "     epoch 2, minibatch 100/100, test error of best model 6.480000 %\n",
      "training @ iter =  200\n",
      "epoch 3, minibatch 100/100, validation error 4.640000 %\n",
      "     epoch 3, minibatch 100/100, test error of best model 4.840000 %\n",
      "training @ iter =  300\n",
      "epoch 4, minibatch 100/100, validation error 3.500000 %\n",
      "     epoch 4, minibatch 100/100, test error of best model 3.940000 %\n",
      "training @ iter =  400\n",
      "epoch 5, minibatch 100/100, validation error 3.020000 %\n",
      "     epoch 5, minibatch 100/100, test error of best model 3.270000 %\n",
      "training @ iter =  500\n",
      "epoch 6, minibatch 100/100, validation error 2.800000 %\n",
      "     epoch 6, minibatch 100/100, test error of best model 2.810000 %\n",
      "training @ iter =  600\n",
      "epoch 7, minibatch 100/100, validation error 2.490000 %\n",
      "     epoch 7, minibatch 100/100, test error of best model 2.480000 %\n",
      "training @ iter =  700\n",
      "epoch 8, minibatch 100/100, validation error 2.290000 %\n",
      "     epoch 8, minibatch 100/100, test error of best model 2.210000 %\n",
      "training @ iter =  800\n",
      "epoch 9, minibatch 100/100, validation error 2.150000 %\n",
      "     epoch 9, minibatch 100/100, test error of best model 2.000000 %\n",
      "training @ iter =  900\n",
      "epoch 10, minibatch 100/100, validation error 1.980000 %\n",
      "     epoch 10, minibatch 100/100, test error of best model 1.910000 %\n",
      "training @ iter =  1000\n",
      "epoch 11, minibatch 100/100, validation error 1.850000 %\n",
      "     epoch 11, minibatch 100/100, test error of best model 1.800000 %\n",
      "training @ iter =  1100\n",
      "epoch 12, minibatch 100/100, validation error 1.790000 %\n",
      "     epoch 12, minibatch 100/100, test error of best model 1.660000 %\n",
      "training @ iter =  1200\n",
      "epoch 13, minibatch 100/100, validation error 1.770000 %\n",
      "     epoch 13, minibatch 100/100, test error of best model 1.580000 %\n",
      "training @ iter =  1300\n",
      "epoch 14, minibatch 100/100, validation error 1.740000 %\n",
      "     epoch 14, minibatch 100/100, test error of best model 1.530000 %\n",
      "training @ iter =  1400\n",
      "epoch 15, minibatch 100/100, validation error 1.680000 %\n",
      "     epoch 15, minibatch 100/100, test error of best model 1.490000 %\n",
      "training @ iter =  1500\n",
      "epoch 16, minibatch 100/100, validation error 1.620000 %\n",
      "     epoch 16, minibatch 100/100, test error of best model 1.430000 %\n",
      "training @ iter =  1600\n",
      "epoch 17, minibatch 100/100, validation error 1.580000 %\n",
      "     epoch 17, minibatch 100/100, test error of best model 1.430000 %\n",
      "training @ iter =  1700\n",
      "epoch 18, minibatch 100/100, validation error 1.560000 %\n",
      "     epoch 18, minibatch 100/100, test error of best model 1.400000 %\n",
      "training @ iter =  1800\n",
      "epoch 19, minibatch 100/100, validation error 1.550000 %\n",
      "     epoch 19, minibatch 100/100, test error of best model 1.380000 %\n",
      "training @ iter =  1900\n",
      "epoch 20, minibatch 100/100, validation error 1.520000 %\n",
      "     epoch 20, minibatch 100/100, test error of best model 1.300000 %\n",
      "training @ iter =  2000\n",
      "epoch 21, minibatch 100/100, validation error 1.500000 %\n",
      "     epoch 21, minibatch 100/100, test error of best model 1.280000 %\n",
      "training @ iter =  2100\n",
      "epoch 22, minibatch 100/100, validation error 1.470000 %\n",
      "     epoch 22, minibatch 100/100, test error of best model 1.260000 %\n",
      "training @ iter =  2200\n",
      "epoch 23, minibatch 100/100, validation error 1.430000 %\n",
      "     epoch 23, minibatch 100/100, test error of best model 1.240000 %\n",
      "training @ iter =  2300\n",
      "epoch 24, minibatch 100/100, validation error 1.390000 %\n",
      "     epoch 24, minibatch 100/100, test error of best model 1.220000 %\n",
      "training @ iter =  2400\n",
      "epoch 25, minibatch 100/100, validation error 1.370000 %\n",
      "     epoch 25, minibatch 100/100, test error of best model 1.180000 %\n",
      "training @ iter =  2500\n",
      "epoch 26, minibatch 100/100, validation error 1.350000 %\n",
      "     epoch 26, minibatch 100/100, test error of best model 1.170000 %\n",
      "training @ iter =  2600\n",
      "epoch 27, minibatch 100/100, validation error 1.320000 %\n",
      "     epoch 27, minibatch 100/100, test error of best model 1.150000 %\n",
      "training @ iter =  2700\n",
      "epoch 28, minibatch 100/100, validation error 1.310000 %\n",
      "     epoch 28, minibatch 100/100, test error of best model 1.130000 %\n",
      "training @ iter =  2800\n",
      "epoch 29, minibatch 100/100, validation error 1.270000 %\n",
      "     epoch 29, minibatch 100/100, test error of best model 1.100000 %\n",
      "training @ iter =  2900\n",
      "epoch 30, minibatch 100/100, validation error 1.260000 %\n",
      "     epoch 30, minibatch 100/100, test error of best model 1.090000 %\n",
      "training @ iter =  3000\n",
      "epoch 31, minibatch 100/100, validation error 1.240000 %\n",
      "     epoch 31, minibatch 100/100, test error of best model 1.090000 %\n",
      "training @ iter =  3100\n",
      "epoch 32, minibatch 100/100, validation error 1.230000 %\n",
      "     epoch 32, minibatch 100/100, test error of best model 1.090000 %\n",
      "training @ iter =  3200\n",
      "epoch 33, minibatch 100/100, validation error 1.220000 %\n",
      "     epoch 33, minibatch 100/100, test error of best model 1.090000 %\n",
      "training @ iter =  3300\n",
      "epoch 34, minibatch 100/100, validation error 1.210000 %\n",
      "     epoch 34, minibatch 100/100, test error of best model 1.080000 %\n",
      "training @ iter =  3400\n",
      "epoch 35, minibatch 100/100, validation error 1.200000 %\n",
      "     epoch 35, minibatch 100/100, test error of best model 1.060000 %\n",
      "training @ iter =  3500\n",
      "epoch 36, minibatch 100/100, validation error 1.200000 %\n",
      "training @ iter =  3600\n",
      "epoch 37, minibatch 100/100, validation error 1.190000 %\n",
      "     epoch 37, minibatch 100/100, test error of best model 1.050000 %\n",
      "training @ iter =  3700\n",
      "epoch 38, minibatch 100/100, validation error 1.180000 %\n",
      "     epoch 38, minibatch 100/100, test error of best model 1.070000 %\n",
      "training @ iter =  3800\n",
      "epoch 39, minibatch 100/100, validation error 1.180000 %\n",
      "training @ iter =  3900\n",
      "epoch 40, minibatch 100/100, validation error 1.170000 %\n",
      "     epoch 40, minibatch 100/100, test error of best model 1.060000 %\n",
      "training @ iter =  4000\n",
      "epoch 41, minibatch 100/100, validation error 1.150000 %\n",
      "     epoch 41, minibatch 100/100, test error of best model 1.060000 %\n",
      "training @ iter =  4100\n",
      "epoch 42, minibatch 100/100, validation error 1.150000 %\n",
      "training @ iter =  4200\n",
      "epoch 43, minibatch 100/100, validation error 1.110000 %\n",
      "     epoch 43, minibatch 100/100, test error of best model 1.060000 %\n",
      "training @ iter =  4300\n",
      "epoch 44, minibatch 100/100, validation error 1.100000 %\n",
      "     epoch 44, minibatch 100/100, test error of best model 1.060000 %\n",
      "training @ iter =  4400\n",
      "epoch 45, minibatch 100/100, validation error 1.100000 %\n",
      "training @ iter =  4500\n",
      "epoch 46, minibatch 100/100, validation error 1.100000 %\n",
      "training @ iter =  4600\n",
      "epoch 47, minibatch 100/100, validation error 1.090000 %\n",
      "     epoch 47, minibatch 100/100, test error of best model 1.050000 %\n",
      "training @ iter =  4700\n",
      "epoch 48, minibatch 100/100, validation error 1.070000 %\n",
      "     epoch 48, minibatch 100/100, test error of best model 1.040000 %\n",
      "training @ iter =  4800\n",
      "epoch 49, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  4900\n",
      "epoch 50, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  5000\n",
      "epoch 51, minibatch 100/100, validation error 1.080000 %\n",
      "training @ iter =  5100\n",
      "epoch 52, minibatch 100/100, validation error 1.080000 %\n",
      "training @ iter =  5200\n",
      "epoch 53, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  5300\n",
      "epoch 54, minibatch 100/100, validation error 1.050000 %\n",
      "     epoch 54, minibatch 100/100, test error of best model 1.030000 %\n",
      "training @ iter =  5400\n",
      "epoch 55, minibatch 100/100, validation error 1.060000 %\n",
      "training @ iter =  5500\n",
      "epoch 56, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  5600\n",
      "epoch 57, minibatch 100/100, validation error 1.060000 %\n",
      "training @ iter =  5700\n",
      "epoch 58, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  5800\n",
      "epoch 59, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  5900\n",
      "epoch 60, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  6000\n",
      "epoch 61, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  6100\n",
      "epoch 62, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  6200\n",
      "epoch 63, minibatch 100/100, validation error 1.080000 %\n",
      "training @ iter =  6300\n",
      "epoch 64, minibatch 100/100, validation error 1.080000 %\n",
      "training @ iter =  6400\n",
      "epoch 65, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  6500\n",
      "epoch 66, minibatch 100/100, validation error 1.070000 %\n",
      "training @ iter =  6600\n",
      "epoch 67, minibatch 100/100, validation error 1.060000 %\n",
      "training @ iter =  6700\n",
      "epoch 68, minibatch 100/100, validation error 1.060000 %\n",
      "training @ iter =  6800\n",
      "epoch 69, minibatch 100/100, validation error 1.040000 %\n",
      "     epoch 69, minibatch 100/100, test error of best model 0.970000 %\n",
      "training @ iter =  6900\n",
      "epoch 70, minibatch 100/100, validation error 1.030000 %\n",
      "     epoch 70, minibatch 100/100, test error of best model 0.970000 %\n",
      "training @ iter =  7000\n",
      "epoch 71, minibatch 100/100, validation error 1.040000 %\n",
      "training @ iter =  7100\n",
      "epoch 72, minibatch 100/100, validation error 1.030000 %\n",
      "training @ iter =  7200\n",
      "epoch 73, minibatch 100/100, validation error 1.030000 %\n",
      "training @ iter =  7300\n",
      "epoch 74, minibatch 100/100, validation error 1.020000 %\n",
      "     epoch 74, minibatch 100/100, test error of best model 0.990000 %\n",
      "training @ iter =  7400\n",
      "epoch 75, minibatch 100/100, validation error 1.010000 %\n",
      "     epoch 75, minibatch 100/100, test error of best model 1.000000 %\n",
      "training @ iter =  7500\n",
      "epoch 76, minibatch 100/100, validation error 1.000000 %\n",
      "     epoch 76, minibatch 100/100, test error of best model 1.000000 %\n",
      "training @ iter =  7600\n",
      "epoch 77, minibatch 100/100, validation error 1.000000 %\n",
      "training @ iter =  7700\n",
      "epoch 78, minibatch 100/100, validation error 1.000000 %\n",
      "training @ iter =  7800\n",
      "epoch 79, minibatch 100/100, validation error 0.990000 %\n",
      "     epoch 79, minibatch 100/100, test error of best model 1.000000 %\n",
      "training @ iter =  7900\n",
      "epoch 80, minibatch 100/100, validation error 0.980000 %\n",
      "     epoch 80, minibatch 100/100, test error of best model 1.000000 %\n",
      "training @ iter =  8000\n",
      "epoch 81, minibatch 100/100, validation error 0.980000 %\n",
      "training @ iter =  8100\n",
      "epoch 82, minibatch 100/100, validation error 0.980000 %\n",
      "training @ iter =  8200\n",
      "epoch 83, minibatch 100/100, validation error 0.970000 %\n",
      "     epoch 83, minibatch 100/100, test error of best model 0.990000 %\n",
      "training @ iter =  8300\n",
      "epoch 84, minibatch 100/100, validation error 0.980000 %\n",
      "training @ iter =  8400\n",
      "epoch 85, minibatch 100/100, validation error 0.960000 %\n",
      "     epoch 85, minibatch 100/100, test error of best model 0.990000 %\n",
      "training @ iter =  8500\n",
      "epoch 86, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  8600\n",
      "epoch 87, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  8700\n",
      "epoch 88, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  8800\n",
      "epoch 89, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  8900\n",
      "epoch 90, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9000\n",
      "epoch 91, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9100\n",
      "epoch 92, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9200\n",
      "epoch 93, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9300\n",
      "epoch 94, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9400\n",
      "epoch 95, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9500\n",
      "epoch 96, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9600\n",
      "epoch 97, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9700\n",
      "epoch 98, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9800\n",
      "epoch 99, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  9900\n",
      "epoch 100, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  10000\n",
      "epoch 101, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  10100\n",
      "epoch 102, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  10200\n",
      "epoch 103, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  10300\n",
      "epoch 104, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  10400\n",
      "epoch 105, minibatch 100/100, validation error 0.950000 %\n",
      "     epoch 105, minibatch 100/100, test error of best model 0.960000 %\n",
      "training @ iter =  10500\n",
      "epoch 106, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  10600\n",
      "epoch 107, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  10700\n",
      "epoch 108, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  10800\n",
      "epoch 109, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  10900\n",
      "epoch 110, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  11000\n",
      "epoch 111, minibatch 100/100, validation error 0.930000 %\n",
      "     epoch 111, minibatch 100/100, test error of best model 0.940000 %\n",
      "training @ iter =  11100\n",
      "epoch 112, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  11200\n",
      "epoch 113, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  11300\n",
      "epoch 114, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  11400\n",
      "epoch 115, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  11500\n",
      "epoch 116, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  11600\n",
      "epoch 117, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  11700\n",
      "epoch 118, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  11800\n",
      "epoch 119, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  11900\n",
      "epoch 120, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  12000\n",
      "epoch 121, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  12100\n",
      "epoch 122, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  12200\n",
      "epoch 123, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  12300\n",
      "epoch 124, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  12400\n",
      "epoch 125, minibatch 100/100, validation error 0.930000 %\n",
      "training @ iter =  12500\n",
      "epoch 126, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  12600\n",
      "epoch 127, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  12700\n",
      "epoch 128, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  12800\n",
      "epoch 129, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  12900\n",
      "epoch 130, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13000\n",
      "epoch 131, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13100\n",
      "epoch 132, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13200\n",
      "epoch 133, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13300\n",
      "epoch 134, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13400\n",
      "epoch 135, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13500\n",
      "epoch 136, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13600\n",
      "epoch 137, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13700\n",
      "epoch 138, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13800\n",
      "epoch 139, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  13900\n",
      "epoch 140, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14000\n",
      "epoch 141, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14100\n",
      "epoch 142, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14200\n",
      "epoch 143, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14300\n",
      "epoch 144, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14400\n",
      "epoch 145, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14500\n",
      "epoch 146, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14600\n",
      "epoch 147, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14700\n",
      "epoch 148, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14800\n",
      "epoch 149, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  14900\n",
      "epoch 150, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15000\n",
      "epoch 151, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15100\n",
      "epoch 152, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15200\n",
      "epoch 153, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  15300\n",
      "epoch 154, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15400\n",
      "epoch 155, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15500\n",
      "epoch 156, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15600\n",
      "epoch 157, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15700\n",
      "epoch 158, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15800\n",
      "epoch 159, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  15900\n",
      "epoch 160, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  16000\n",
      "epoch 161, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  16100\n",
      "epoch 162, minibatch 100/100, validation error 0.940000 %\n",
      "training @ iter =  16200\n",
      "epoch 163, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16300\n",
      "epoch 164, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16400\n",
      "epoch 165, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16500\n",
      "epoch 166, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16600\n",
      "epoch 167, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16700\n",
      "epoch 168, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16800\n",
      "epoch 169, minibatch 100/100, validation error 0.950000 %\n",
      "training @ iter =  16900\n",
      "epoch 170, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17000\n",
      "epoch 171, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17100\n",
      "epoch 172, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17200\n",
      "epoch 173, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17300\n",
      "epoch 174, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17400\n",
      "epoch 175, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17500\n",
      "epoch 176, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17600\n",
      "epoch 177, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17700\n",
      "epoch 178, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17800\n",
      "epoch 179, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  17900\n",
      "epoch 180, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18000\n",
      "epoch 181, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18100\n",
      "epoch 182, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18200\n",
      "epoch 183, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18300\n",
      "epoch 184, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18400\n",
      "epoch 185, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18500\n",
      "epoch 186, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18600\n",
      "epoch 187, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18700\n",
      "epoch 188, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18800\n",
      "epoch 189, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  18900\n",
      "epoch 190, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19000\n",
      "epoch 191, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19100\n",
      "epoch 192, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19200\n",
      "epoch 193, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19300\n",
      "epoch 194, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19400\n",
      "epoch 195, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19500\n",
      "epoch 196, minibatch 100/100, validation error 0.960000 %\n",
      "training @ iter =  19600\n",
      "epoch 197, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  19700\n",
      "epoch 198, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  19800\n",
      "epoch 199, minibatch 100/100, validation error 0.970000 %\n",
      "training @ iter =  19900\n",
      "epoch 200, minibatch 100/100, validation error 0.970000 %\n",
      "Optimization complete.\n",
      "Best validation score of 0.930000 % obtained at iteration 11100, with test performance 0.940000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file convolutional_mlp.py ran for 8.45m\n"
     ]
    }
   ],
   "source": [
    "%run convolutional_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cpu\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floatX (('float64', 'float32')) \n",
      "    Doc:  Default floating-point precision for python casts\n",
      "    Value:  float64\n",
      "\n",
      "warn_float64 (('ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  Do an action when a tensor variable with float64 dtype is created. They can't be run on the GPU with the current(old) gpu back-end and are slow with gamer GPUs.\n",
      "    Value:  ignore\n",
      "\n",
      "cast_policy (('custom', 'numpy+floatX')) \n",
      "    Doc:  Rules for implicit type casting\n",
      "    Value:  custom\n",
      "\n",
      "int_division (('int', 'raise', 'floatX')) \n",
      "    Doc:  What to do when one computes x / y, where both x and y are of integer types\n",
      "    Value:  int\n",
      "\n",
      "device (cpu, gpu*, opencl*, cuda*) \n",
      "    Doc:  Default device for computations. If gpu*, change the default to try to move computation to it and to put shared variable of float32 on it. Do not use upper case letters, only lower case even if NVIDIA use capital letters.\n",
      "    Value:  cpu\n",
      "\n",
      "gpuarray.init_device (<type 'str'>) \n",
      "    Doc:  \n",
      "             Device to initialize for gpuarray use without moving\n",
      "             computations automatically.\n",
      "             \n",
      "    Value:  \n",
      "\n",
      "init_gpu_device (('', 'gpu', 'gpu0', 'gpu1', 'gpu2', 'gpu3', 'gpu4', 'gpu5', 'gpu6', 'gpu7', 'gpu8', 'gpu9', 'gpu10', 'gpu11', 'gpu12', 'gpu13', 'gpu14', 'gpu15')) \n",
      "    Doc:  Initialize the gpu device to use, works only if device=cpu. Unlike 'device', setting this option will NOT move computations, nor shared variables, to the specified GPU. It can be used to run GPU-specific tests on a particular GPU.\n",
      "    Value:  \n",
      "\n",
      "force_device (<function booltype at 0x7fd828116230>) \n",
      "    Doc:  Raise an error if we can't use the specified device\n",
      "    Value:  False\n",
      "\n",
      "print_active_device (<function booltype at 0x7fd828116398>) \n",
      "    Doc:  Print active device at when the GPU device is initialized.\n",
      "    Value:  True\n",
      "\n",
      "mode (('Mode', 'ProfileMode', 'DebugMode', 'FAST_RUN', 'FAST_COMPILE', 'PROFILE_MODE', 'DEBUG_MODE')) \n",
      "    Doc:  Default compilation mode\n",
      "    Value:  Mode\n",
      "\n",
      "cxx (<type 'str'>) \n",
      "    Doc:  The C++ compiler to use. Currently only g++ is supported, but supporting additional compilers should not be too difficult. If it is empty, no C++ code is compiled.\n",
      "    Value:  /usr/bin/g++\n",
      "\n",
      "linker (('cvm', 'c|py', 'py', 'c', 'c|py_nogc', 'vm', 'vm_nogc', 'cvm_nogc')) \n",
      "    Doc:  Default linker used if the theano flags mode is Mode or ProfileMode(deprecated)\n",
      "    Value:  cvm\n",
      "\n",
      "allow_gc (<function booltype at 0x7fd8281169b0>) \n",
      "    Doc:  Do we default to delete intermediate results during Theano function calls? Doing so lowers the memory requirement, but asks that we reallocate memory at the next function call. This is implemented for the default linker, but may not work for all linkers.\n",
      "    Value:  True\n",
      "\n",
      "optimizer (('fast_run', 'merge', 'fast_compile', 'None')) \n",
      "    Doc:  Default optimizer. If not None, will use this linker with the Mode object (not ProfileMode(deprecated) or DebugMode)\n",
      "    Value:  fast_run\n",
      "\n",
      "optimizer_verbose (<function booltype at 0x7fd828116b90>) \n",
      "    Doc:  If True, we print all optimization being applied\n",
      "    Value:  False\n",
      "\n",
      "on_opt_error (('warn', 'raise', 'pdb')) \n",
      "    Doc:  What to do when an optimization crashes: warn and skip it, raise the exception, or fall into the pdb debugger.\n",
      "    Value:  warn\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7fd82811b110>\n",
      "    Doc:  This config option was removed in 0.5: do not use it!\n",
      "    Value:  True\n",
      "\n",
      "nocleanup (<function booltype at 0x7fd828116de8>) \n",
      "    Doc:  Suppress the deletion of code files that did not compile cleanly\n",
      "    Value:  False\n",
      "\n",
      "on_unused_input (('raise', 'warn', 'ignore')) \n",
      "    Doc:  What to do if a variable in the 'inputs' list of  theano.function() is not used in the graph.\n",
      "    Value:  raise\n",
      "\n",
      "tensor.cmp_sloppy (<type 'int'>) \n",
      "    Doc:  Relax tensor._allclose (0) not at all, (1) a bit, (2) more\n",
      "    Value:  0\n",
      "\n",
      "tensor.local_elemwise_fusion (<function booltype at 0x7fd82811c140>) \n",
      "    Doc:  Enable or not in fast_run mode(fast_run optimization) the elemwise fusion optimization\n",
      "    Value:  True\n",
      "\n",
      "gpu.local_elemwise_fusion (<function booltype at 0x7fd82811c2a8>) \n",
      "    Doc:  Enable or not in fast_run mode(fast_run optimization) the gpu elemwise fusion optimization\n",
      "    Value:  True\n",
      "\n",
      "lib.amdlibm (<function booltype at 0x7fd82811c410>) \n",
      "    Doc:  Use amd's amdlibm numerical library\n",
      "    Value:  False\n",
      "\n",
      "gpuelemwise.sync (<function booltype at 0x7fd82811c578>) \n",
      "    Doc:  when true, wait that the gpu fct finished and check it error code.\n",
      "    Value:  True\n",
      "\n",
      "traceback.limit (<type 'int'>) \n",
      "    Doc:  The number of stack to trace. -1 mean all.\n",
      "    Value:  7\n",
      "\n",
      "experimental.mrg (<function booltype at 0x7fd82811c758>) \n",
      "    Doc:  Another random number generator that work on the gpu\n",
      "    Value:  False\n",
      "\n",
      "experimental.unpickle_gpu_on_cpu (<function booltype at 0x7fd82811c8c0>) \n",
      "    Doc:  Allow unpickling of pickled CudaNdarrays as numpy.ndarrays.This is useful, if you want to open a CudaNdarray without having cuda installed.If you have cuda installed, this will force unpickling tobe done on the cpu to numpy.ndarray.Please be aware that this may get you access to the data,however, trying to unpicke gpu functions will not succeed.This flag is experimental and may be removed any time, whengpu<>cpu transparency is solved.\n",
      "    Value:  False\n",
      "\n",
      "numpy.seterr_all (('ignore', 'warn', 'raise', 'call', 'print', 'log', 'None')) \n",
      "    Doc:  (\"Sets numpy's behaviour for floating-point errors, \", \"see numpy.seterr. 'None' means not to change numpy's default, which can be different for different numpy releases. This flag sets the default behaviour for all kinds of floating-point errors, its effect can be overriden for specific errors by the following flags: seterr_divide, seterr_over, seterr_under and seterr_invalid.\")\n",
      "    Value:  ignore\n",
      "\n",
      "numpy.seterr_divide (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for division by zero, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_over (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for floating-point overflow, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_under (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for floating-point underflow, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "numpy.seterr_invalid (('None', 'ignore', 'warn', 'raise', 'call', 'print', 'log')) \n",
      "    Doc:  Sets numpy's behavior for invalid floating-point operation, see numpy.seterr. 'None' means using the default, defined by numpy.seterr_all.\n",
      "    Value:  None\n",
      "\n",
      "warn.ignore_bug_before (('0.6', 'None', 'all', '0.3', '0.4', '0.4.1', '0.5', '0.7')) \n",
      "    Doc:  If 'None', we warn about all Theano bugs found by default. If 'all', we don't warn about Theano bugs found by default. If a version, we print only the warnings relative to Theano bugs found after that version. Warning for specific bugs can be configured with specific [warn] flags.\n",
      "    Value:  0.6\n",
      "\n",
      "warn.argmax_pushdown_bug (<function booltype at 0x7fd82811cde8>) \n",
      "    Doc:  Warn if in past version of Theano we generated a bug with the theano.tensor.nnet.nnet.local_argmax_pushdown optimization. Was fixed 27 may 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.gpusum_01_011_0111_bug (<function booltype at 0x7fd82811cf50>) \n",
      "    Doc:  Warn if we are in a case where old version of Theano had a silent bug with GpuSum pattern 01,011 and 0111 when the first dimensions was bigger then 4096. Was fixed 31 may 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.sum_sum_bug (<function booltype at 0x7fd828120140>) \n",
      "    Doc:  Warn if we are in a case where Theano version between version 9923a40c7b7a and the 2 august 2010 (fixed date), generated an error in that case. This happens when there are 2 consecutive sums in the graph, bad code was generated. Was fixed 2 August 2010\n",
      "    Value:  False\n",
      "\n",
      "warn.sum_div_dimshuffle_bug (<function booltype at 0x7fd8281202a8>) \n",
      "    Doc:  Warn if previous versions of Theano (between rev. 3bd9b789f5e8, 2010-06-16, and cfc6322e5ad4, 2010-08-03) would have given incorrect result. This bug was triggered by sum of division of dimshuffled tensors.\n",
      "    Value:  False\n",
      "\n",
      "warn.subtensor_merge_bug (<function booltype at 0x7fd828120410>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.5rc2) could have given incorrect results when indexing into a subtensor with negative stride (for instance, for instance, x[a:b:-1][c]).\n",
      "    Value:  False\n",
      "\n",
      "warn.gpu_set_subtensor1 (<function booltype at 0x7fd828120578>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.6) could have given incorrect results when moving to the gpu set_subtensor(x[int vector], new_value)\n",
      "    Value:  False\n",
      "\n",
      "warn.vm_gc_bug (<function booltype at 0x7fd8281206e0>) \n",
      "    Doc:  There was a bug that existed in the default Theano configuration, only in the development version between July 5th 2012 and July 30th 2012. This was not in a released version. If your code was affected by this bug, a warning will be printed during the code execution if you use the `linker=vm,vm.lazy=True,warn.vm_gc_bug=True` Theano flags. This warning is disabled by default as the bug was not released.\n",
      "    Value:  False\n",
      "\n",
      "warn.signal_conv2d_interface (<function booltype at 0x7fd828120848>) \n",
      "    Doc:  Warn we use the new signal.conv2d() when its interface changed mid June 2014\n",
      "    Value:  True\n",
      "\n",
      "warn.reduce_join (<function booltype at 0x7fd8281209b0>) \n",
      "    Doc:  Your current code is fine, but Theano versions prior to 0.7 (or this development version) might have given an incorrect result. To disable this warning, set the Theano flag warn.reduce_join to False. The problem was an optimization, that modified the pattern \"Reduce{scalar.op}(Join(axis=0, a, b), axis=0)\", did not check the reduction axis. So if the reduction axis was not 0, you got a wrong answer.\n",
      "    Value:  True\n",
      "\n",
      "warn.inc_set_subtensor1 (<function booltype at 0x7fd828120b18>) \n",
      "    Doc:  Warn if previous versions of Theano (before 0.7) could have given incorrect results for inc_subtensor and set_subtensor when using some patterns of advanced indexing (indexing with one vector or matrix of ints).\n",
      "    Value:  True\n",
      "\n",
      "compute_test_value (('off', 'ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  If 'True', Theano will run each op at graph build time, using Constants, SharedVariables and the tag 'test_value' as inputs to the function. This helps the user track down problems in the graph before it gets optimized.\n",
      "    Value:  off\n",
      "\n",
      "compute_test_value_opt (('off', 'ignore', 'warn', 'raise', 'pdb')) \n",
      "    Doc:  For debugging Theano optimization only. Same as compute_test_value, but is used during Theano optimization\n",
      "    Value:  off\n",
      "\n",
      "unpickle_function (<function booltype at 0x7fd828120d70>) \n",
      "    Doc:  Replace unpickled Theano functions with None. This is useful to unpickle old graphs that pickled them when it shouldn't\n",
      "    Value:  True\n",
      "\n",
      "reoptimize_unpickled_function (<function booltype at 0x7fd828120ed8>) \n",
      "    Doc:  Re-optimize the graph when a theano function is unpickled from the disk.\n",
      "    Value:  True\n",
      "\n",
      "exception_verbosity (('low', 'high')) \n",
      "    Doc:  If 'low', the text of exceptions will generally refer to apply nodes with short names such as Elemwise{add_no_inplace}. If 'high', some exceptions will also refer to apply nodes with long descriptions  like:\n",
      "        A. Elemwise{add_no_inplace}\n",
      "                B. log_likelihood_v_given_h\n",
      "                C. log_likelihood_h\n",
      "    Value:  low\n",
      "\n",
      "openmp (<function booltype at 0x7fd828123140>) \n",
      "    Doc:  Allow (or not) parallel computation on the CPU with OpenMP. This is the default value used when creating an Op that supports OpenMP parallelization. It is preferable to define it via the Theano configuration file ~/.theanorc or with the environment variable THEANO_FLAGS. Parallelization is only done for some operations that implement it, and even for operations that implement parallelism, each operation is free to respect this flag or not. You can control the number of threads used with the environment variable OMP_NUM_THREADS. If it is set to 1, we disable openmp in Theano by default.\n",
      "    Value:  False\n",
      "\n",
      "openmp_elemwise_minsize (<type 'int'>) \n",
      "    Doc:  If OpenMP is enabled, this is the minimum size of vectors for which the openmp parallelization is enabled in element wise ops.\n",
      "    Value:  200000\n",
      "\n",
      "check_input (<function booltype at 0x7fd828123320>) \n",
      "    Doc:  Specify if types should check their input in their C code. It can be used to speed up compilation, reduce overhead (particularly for scalars) and reduce the number of generated C files.\n",
      "    Value:  True\n",
      "\n",
      "cache_optimizations (<function booltype at 0x7fd828123488>) \n",
      "    Doc:  WARNING: work in progress, does not work yet. Specify if the optimization cache should be used. This cache will any optimized graph and its optimization. Actually slow downs a lot the first optimization, and could possibly still contains some bugs. Use at your own risks.\n",
      "    Value:  False\n",
      "\n",
      "gcc.cxxflags (<type 'str'>) \n",
      "    Doc:  Extra compiler flags for gcc\n",
      "    Value:  \n",
      "\n",
      "compile.wait (<type 'int'>) \n",
      "    Doc:  Time to wait before retrying to aquire the compile lock.\n",
      "    Value:  5\n",
      "\n",
      "compile.timeout (<type 'int'>) \n",
      "    Doc:  In seconds, time that a process will wait before deciding to\n",
      "override an existing lock. An override only happens when the existing\n",
      "lock is held by the same owner *and* has not been 'refreshed' by this\n",
      "owner for more than this period. Refreshes are done every half timeout\n",
      "period for running processes.\n",
      "    Value:  120\n",
      "\n",
      "compiledir_format (<type 'str'>) \n",
      "    Doc:  Format string for platform-dependent compiled module subdirectory\n",
      "(relative to base_compiledir). Available keys: gxx_version, hostname,\n",
      "numpy_version, platform, processor, python_bitwidth,\n",
      "python_int_bitwidth, python_version, short_platform, theano_version.\n",
      "Defaults to 'compiledir_%(short_platform)s-%(processor)s-%(python_vers\n",
      "ion)s-%(python_bitwidth)s'.\n",
      "    Value:  compiledir_%(short_platform)s-%(processor)s-%(python_version)s-%(python_bitwidth)s\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7fd7fe965a50>\n",
      "    Doc:  platform-independent root directory for compiled modules\n",
      "    Value:  /home/ubuntu/.theano\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7fd7fe965b10>\n",
      "    Doc:  platform-dependent cache directory for compiled modules\n",
      "    Value:  /home/ubuntu/.theano/compiledir_Linux-3.13--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.11-64\n",
      "\n",
      "cmodule.mac_framework_link (<function booltype at 0x7fd7fe966aa0>) \n",
      "    Doc:  If set to True, breaks certain MacOS installations with the infamous Bus Error\n",
      "    Value:  False\n",
      "\n",
      "cmodule.warn_no_version (<function booltype at 0x7fd7fe966c08>) \n",
      "    Doc:  If True, will print a warning when compiling one or more Op with C code that can't be cached because there is no c_code_cache_version() function associated to at least one of those Ops.\n",
      "    Value:  False\n",
      "\n",
      "cmodule.remove_gxx_opt (<function booltype at 0x7fd7fe966d70>) \n",
      "    Doc:  If True, will remove the -O* parameter passed to g++.This is useful to debug in gdb modules compiled by Theano.The parameter -g is passed by default to g++\n",
      "    Value:  False\n",
      "\n",
      "cmodule.compilation_warning (<function booltype at 0x7fd7fe966ed8>) \n",
      "    Doc:  If True, will print compilation warnings.\n",
      "    Value:  False\n",
      "\n",
      "cmodule.preload_cache (<function booltype at 0x7fd7fe96f0c8>) \n",
      "    Doc:  If set to True, will preload the C module cache at import time\n",
      "    Value:  False\n",
      "\n",
      "metaopt.verbose (<function booltype at 0x7fd8212c7938>) \n",
      "    Doc:  Enable verbose output for meta optimizers\n",
      "    Value:  False\n",
      "\n",
      "optdb.position_cutoff (<type 'float'>) \n",
      "    Doc:  Where to stop eariler during optimization. It represent the position of the optimizer where to stop.\n",
      "    Value:  inf\n",
      "\n",
      "optdb.max_use_ratio (<type 'float'>) \n",
      "    Doc:  A ratio that prevent infinite loop in EquilibriumOptimizer.\n",
      "    Value:  5.0\n",
      "\n",
      "profile (<function booltype at 0x7fd8212e55f0>) \n",
      "    Doc:  If VM should collect profile information\n",
      "    Value:  False\n",
      "\n",
      "profile_optimizer (<function booltype at 0x7fd8212e5758>) \n",
      "    Doc:  If VM should collect optimizer profile information\n",
      "    Value:  False\n",
      "\n",
      "profile_memory (<function booltype at 0x7fd8212e58c0>) \n",
      "    Doc:  If VM should collect memory profile information and print it\n",
      "    Value:  False\n",
      "\n",
      "<theano.configparser.ConfigParam object at 0x7fd8212f7950>\n",
      "    Doc:  Useful only for the vm linkers. When lazy is None, auto detect if lazy evaluation is needed and use the apropriate version. If lazy is True/False, force the version used between Loop/LoopGC and Stack.\n",
      "    Value:  None\n",
      "\n",
      "optimizer_excluding (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will remove optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "optimizer_including (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will add optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "optimizer_requiring (<type 'str'>) \n",
      "    Doc:  When using the default mode, we will require optimizer with these tags. Separate tags with ':'.\n",
      "    Value:  \n",
      "\n",
      "DebugMode.patience (<type 'int'>) \n",
      "    Doc:  Optimize graph this many times to detect inconsistency\n",
      "    Value:  10\n",
      "\n",
      "DebugMode.check_c (<function booltype at 0x7fd8212af230>) \n",
      "    Doc:  Run C implementations where possible\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_py (<function booltype at 0x7fd8212af398>) \n",
      "    Doc:  Run Python implementations where possible\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_finite (<function booltype at 0x7fd8212af500>) \n",
      "    Doc:  True -> complain about NaN/Inf results\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_strides (<type 'int'>) \n",
      "    Doc:  Check that Python- and C-produced ndarrays have same strides.  On difference: (0) - ignore, (1) warn, or (2) raise error\n",
      "    Value:  1\n",
      "\n",
      "DebugMode.warn_input_not_reused (<function booltype at 0x7fd8212af758>) \n",
      "    Doc:  Generate a warning when destroy_map or view_map says that an op works inplace, but the op did not reuse the input for its output.\n",
      "    Value:  True\n",
      "\n",
      "DebugMode.check_preallocated_output (<type 'str'>) \n",
      "    Doc:  Test thunks with pre-allocated memory as output storage. This is a list of strings separated by \":\". Valid values are: \"initial\" (initial storage in storage map, happens with Scan),\"previous\" (previously-returned memory), \"c_contiguous\", \"f_contiguous\", \"strided\" (positive and negative strides), \"wrong_size\" (larger and smaller dimensions), and \"ALL\" (all of the above).\n",
      "    Value:  \n",
      "\n",
      "DebugMode.check_preallocated_output_ndim (<type 'int'>) \n",
      "    Doc:  When testing with \"strided\" preallocated output memory, test all combinations of strides over that number of (inner-most) dimensions. You may want to reduce that number to reduce memory or time usage, but it is advised to keep a minimum of 2.\n",
      "    Value:  4\n",
      "\n",
      "profiling.time_thunks (<function booltype at 0x7fd8210388c0>) \n",
      "    Doc:  Time individual thunks when profiling\n",
      "    Value:  True\n",
      "\n",
      "profiling.n_apply (<type 'int'>) \n",
      "    Doc:  Number of Apply instances to print by default\n",
      "    Value:  20\n",
      "\n",
      "profiling.n_ops (<type 'int'>) \n",
      "    Doc:  Number of Ops to print by default\n",
      "    Value:  20\n",
      "\n",
      "profiling.output_line_width (<type 'int'>) \n",
      "    Doc:  Max line width for the profiling output\n",
      "    Value:  512\n",
      "\n",
      "profiling.min_memory_size (<type 'int'>) \n",
      "    Doc:  For the memory profile, do not print Apply nodes if the size\n",
      "             of their outputs (in bytes) is lower than this threshold\n",
      "    Value:  1024\n",
      "\n",
      "profiling.min_peak_memory (<function booltype at 0x7fd821038de8>) \n",
      "    Doc:  The min peak memory usage of the order\n",
      "    Value:  False\n",
      "\n",
      "profiling.destination (<type 'str'>) \n",
      "    Doc:  \n",
      "             File destination of the profiling output\n",
      "             \n",
      "    Value:  stderr\n",
      "\n",
      "ProfileMode.n_apply_to_print (<type 'int'>) \n",
      "    Doc:  Number of apply instances to print by default\n",
      "    Value:  15\n",
      "\n",
      "ProfileMode.n_ops_to_print (<type 'int'>) \n",
      "    Doc:  Number of ops to print by default\n",
      "    Value:  20\n",
      "\n",
      "ProfileMode.min_memory_size (<type 'int'>) \n",
      "    Doc:  For the memory profile, do not print apply nodes if the size\n",
      " of their outputs (in bytes) is lower then this threshold\n",
      "    Value:  1024\n",
      "\n",
      "ProfileMode.profile_memory (<function booltype at 0x7fd82104d0c8>) \n",
      "    Doc:  Enable profiling of memory used by Theano functions\n",
      "    Value:  False\n",
      "\n",
      "on_shape_error (('warn', 'raise')) \n",
      "    Doc:  warn: print a warning and use the default value. raise: raise an error\n",
      "    Value:  warn\n",
      "\n",
      "tensor.insert_inplace_optimizer_validate_nb (<type 'int'>) \n",
      "    Doc:  -1: auto, if graph have less then 500 nodes 1, else 10\n",
      "    Value:  -1\n",
      "\n",
      "experimental.local_alloc_elemwise (<function booltype at 0x7fd7f9bde410>) \n",
      "    Doc:  DEPRECATED: If True, enable the experimental optimization local_alloc_elemwise. Generates error if not True. Use optimizer_excluding=local_alloc_elemwise to dsiable.\n",
      "    Value:  True\n",
      "\n",
      "experimental.local_alloc_elemwise_assert (<function booltype at 0x7fd7f9bde488>) \n",
      "    Doc:  When the local_alloc_elemwise is applied, add an assert to highlight shape errors.\n",
      "    Value:  True\n",
      "\n",
      "blas.ldflags (<type 'str'>) \n",
      "    Doc:  lib[s] to include for [Fortran] level-3 blas implementation\n",
      "    Value:  -L/home/ubuntu/miniconda2/envs/theano/lib -lopenblas\n",
      "\n",
      "warn.identify_1pexp_bug (<function booltype at 0x7fd7f486d758>) \n",
      "    Doc:  Warn if Theano versions prior to 7987b51 (2011-12-18) could have yielded a wrong result due to a bug in the is_1pexp function\n",
      "    Value:  False\n",
      "\n",
      "scan.allow_gc (<function booltype at 0x7fd7f411a578>) \n",
      "    Doc:  Allow/disallow gc inside of Scan (default: False)\n",
      "    Value:  False\n",
      "\n",
      "unittests.rseed (<type 'str'>) \n",
      "    Doc:  Seed to use for randomized unit tests. Special value 'random' means using a seed of None.\n",
      "    Value:  666\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import theano;print theano.config1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "... training the model\n",
      "epoch 1, minibatch 83/83, validation error 12.458333 %\n",
      "     epoch 1, minibatch 83/83, test error of best model 12.375000 %\n",
      "epoch 2, minibatch 83/83, validation error 11.010417 %\n",
      "     epoch 2, minibatch 83/83, test error of best model 10.958333 %\n",
      "epoch 3, minibatch 83/83, validation error 10.312500 %\n",
      "     epoch 3, minibatch 83/83, test error of best model 10.312500 %\n",
      "epoch 4, minibatch 83/83, validation error 9.875000 %\n",
      "     epoch 4, minibatch 83/83, test error of best model 9.833333 %\n",
      "epoch 5, minibatch 83/83, validation error 9.562500 %\n",
      "     epoch 5, minibatch 83/83, test error of best model 9.479167 %\n",
      "epoch 6, minibatch 83/83, validation error 9.322917 %\n",
      "     epoch 6, minibatch 83/83, test error of best model 9.291667 %\n",
      "epoch 7, minibatch 83/83, validation error 9.187500 %\n",
      "     epoch 7, minibatch 83/83, test error of best model 9.000000 %\n",
      "epoch 8, minibatch 83/83, validation error 8.989583 %\n",
      "     epoch 8, minibatch 83/83, test error of best model 8.958333 %\n",
      "epoch 9, minibatch 83/83, validation error 8.937500 %\n",
      "     epoch 9, minibatch 83/83, test error of best model 8.812500 %\n",
      "epoch 10, minibatch 83/83, validation error 8.750000 %\n",
      "     epoch 10, minibatch 83/83, test error of best model 8.666667 %\n",
      "epoch 11, minibatch 83/83, validation error 8.666667 %\n",
      "     epoch 11, minibatch 83/83, test error of best model 8.520833 %\n",
      "epoch 12, minibatch 83/83, validation error 8.583333 %\n",
      "     epoch 12, minibatch 83/83, test error of best model 8.416667 %\n",
      "epoch 13, minibatch 83/83, validation error 8.489583 %\n",
      "     epoch 13, minibatch 83/83, test error of best model 8.291667 %\n",
      "epoch 14, minibatch 83/83, validation error 8.427083 %\n",
      "     epoch 14, minibatch 83/83, test error of best model 8.281250 %\n",
      "epoch 15, minibatch 83/83, validation error 8.354167 %\n",
      "     epoch 15, minibatch 83/83, test error of best model 8.270833 %\n",
      "epoch 16, minibatch 83/83, validation error 8.302083 %\n",
      "     epoch 16, minibatch 83/83, test error of best model 8.239583 %\n",
      "epoch 17, minibatch 83/83, validation error 8.250000 %\n",
      "     epoch 17, minibatch 83/83, test error of best model 8.177083 %\n",
      "epoch 18, minibatch 83/83, validation error 8.229167 %\n",
      "     epoch 18, minibatch 83/83, test error of best model 8.062500 %\n",
      "epoch 19, minibatch 83/83, validation error 8.260417 %\n",
      "epoch 20, minibatch 83/83, validation error 8.260417 %\n",
      "epoch 21, minibatch 83/83, validation error 8.208333 %\n",
      "     epoch 21, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 22, minibatch 83/83, validation error 8.187500 %\n",
      "     epoch 22, minibatch 83/83, test error of best model 7.927083 %\n",
      "epoch 23, minibatch 83/83, validation error 8.156250 %\n",
      "     epoch 23, minibatch 83/83, test error of best model 7.958333 %\n",
      "epoch 24, minibatch 83/83, validation error 8.114583 %\n",
      "     epoch 24, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 25, minibatch 83/83, validation error 8.093750 %\n",
      "     epoch 25, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 26, minibatch 83/83, validation error 8.104167 %\n",
      "epoch 27, minibatch 83/83, validation error 8.104167 %\n",
      "epoch 28, minibatch 83/83, validation error 8.052083 %\n",
      "     epoch 28, minibatch 83/83, test error of best model 7.843750 %\n",
      "epoch 29, minibatch 83/83, validation error 8.052083 %\n",
      "epoch 30, minibatch 83/83, validation error 8.031250 %\n",
      "     epoch 30, minibatch 83/83, test error of best model 7.843750 %\n",
      "epoch 31, minibatch 83/83, validation error 8.010417 %\n",
      "     epoch 31, minibatch 83/83, test error of best model 7.833333 %\n",
      "epoch 32, minibatch 83/83, validation error 7.979167 %\n",
      "     epoch 32, minibatch 83/83, test error of best model 7.812500 %\n",
      "epoch 33, minibatch 83/83, validation error 7.947917 %\n",
      "     epoch 33, minibatch 83/83, test error of best model 7.739583 %\n",
      "epoch 34, minibatch 83/83, validation error 7.875000 %\n",
      "     epoch 34, minibatch 83/83, test error of best model 7.729167 %\n",
      "epoch 35, minibatch 83/83, validation error 7.885417 %\n",
      "epoch 36, minibatch 83/83, validation error 7.843750 %\n",
      "     epoch 36, minibatch 83/83, test error of best model 7.697917 %\n",
      "epoch 37, minibatch 83/83, validation error 7.802083 %\n",
      "     epoch 37, minibatch 83/83, test error of best model 7.635417 %\n",
      "epoch 38, minibatch 83/83, validation error 7.812500 %\n",
      "epoch 39, minibatch 83/83, validation error 7.812500 %\n",
      "epoch 40, minibatch 83/83, validation error 7.822917 %\n",
      "epoch 41, minibatch 83/83, validation error 7.791667 %\n",
      "     epoch 41, minibatch 83/83, test error of best model 7.625000 %\n",
      "epoch 42, minibatch 83/83, validation error 7.770833 %\n",
      "     epoch 42, minibatch 83/83, test error of best model 7.614583 %\n",
      "epoch 43, minibatch 83/83, validation error 7.750000 %\n",
      "     epoch 43, minibatch 83/83, test error of best model 7.593750 %\n",
      "epoch 44, minibatch 83/83, validation error 7.739583 %\n",
      "     epoch 44, minibatch 83/83, test error of best model 7.593750 %\n",
      "epoch 45, minibatch 83/83, validation error 7.739583 %\n",
      "epoch 46, minibatch 83/83, validation error 7.739583 %\n",
      "epoch 47, minibatch 83/83, validation error 7.739583 %\n",
      "epoch 48, minibatch 83/83, validation error 7.708333 %\n",
      "     epoch 48, minibatch 83/83, test error of best model 7.583333 %\n",
      "epoch 49, minibatch 83/83, validation error 7.677083 %\n",
      "     epoch 49, minibatch 83/83, test error of best model 7.572917 %\n",
      "epoch 50, minibatch 83/83, validation error 7.677083 %\n",
      "epoch 51, minibatch 83/83, validation error 7.677083 %\n",
      "epoch 52, minibatch 83/83, validation error 7.656250 %\n",
      "     epoch 52, minibatch 83/83, test error of best model 7.541667 %\n",
      "epoch 53, minibatch 83/83, validation error 7.656250 %\n",
      "epoch 54, minibatch 83/83, validation error 7.635417 %\n",
      "     epoch 54, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 55, minibatch 83/83, validation error 7.635417 %\n",
      "epoch 56, minibatch 83/83, validation error 7.635417 %\n",
      "epoch 57, minibatch 83/83, validation error 7.604167 %\n",
      "     epoch 57, minibatch 83/83, test error of best model 7.489583 %\n",
      "epoch 58, minibatch 83/83, validation error 7.583333 %\n",
      "     epoch 58, minibatch 83/83, test error of best model 7.458333 %\n",
      "epoch 59, minibatch 83/83, validation error 7.572917 %\n",
      "     epoch 59, minibatch 83/83, test error of best model 7.468750 %\n",
      "epoch 60, minibatch 83/83, validation error 7.572917 %\n",
      "epoch 61, minibatch 83/83, validation error 7.583333 %\n",
      "epoch 62, minibatch 83/83, validation error 7.572917 %\n",
      "     epoch 62, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 63, minibatch 83/83, validation error 7.562500 %\n",
      "     epoch 63, minibatch 83/83, test error of best model 7.510417 %\n",
      "epoch 64, minibatch 83/83, validation error 7.572917 %\n",
      "epoch 65, minibatch 83/83, validation error 7.562500 %\n",
      "epoch 66, minibatch 83/83, validation error 7.552083 %\n",
      "     epoch 66, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 67, minibatch 83/83, validation error 7.552083 %\n",
      "epoch 68, minibatch 83/83, validation error 7.531250 %\n",
      "     epoch 68, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 69, minibatch 83/83, validation error 7.531250 %\n",
      "epoch 70, minibatch 83/83, validation error 7.510417 %\n",
      "     epoch 70, minibatch 83/83, test error of best model 7.500000 %\n",
      "epoch 71, minibatch 83/83, validation error 7.520833 %\n",
      "epoch 72, minibatch 83/83, validation error 7.510417 %\n",
      "epoch 73, minibatch 83/83, validation error 7.500000 %\n",
      "     epoch 73, minibatch 83/83, test error of best model 7.489583 %\n",
      "Optimization complete with best validation score of 7.500000 %,with test performance 7.489583 %\n",
      "The code run for 74 epochs, with 3.344366 epochs/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file logistic_sgd.py ran for 22.1s\n"
     ]
    }
   ],
   "source": [
    "%run logistic_sgd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "... training\n",
      "training @ iter =  0\n",
      "epoch 1, minibatch 100/100, validation error 9.230000 %\n",
      "     epoch 1, minibatch 100/100, test error of best model 9.520000 %\n",
      "training @ iter =  100\n",
      "epoch 2, minibatch 100/100, validation error 6.180000 %\n",
      "     epoch 2, minibatch 100/100, test error of best model 6.500000 %\n",
      "training @ iter =  200\n",
      "epoch 3, minibatch 100/100, validation error 4.640000 %\n",
      "     epoch 3, minibatch 100/100, test error of best model 4.850000 %\n",
      "training @ iter =  300\n",
      "epoch 4, minibatch 100/100, validation error 3.500000 %\n",
      "     epoch 4, minibatch 100/100, test error of best model 3.910000 %\n",
      "training @ iter =  400\n",
      "epoch 5, minibatch 100/100, validation error 3.020000 %\n",
      "     epoch 5, minibatch 100/100, test error of best model 3.260000 %\n",
      "training @ iter =  500\n",
      "epoch 6, minibatch 100/100, validation error 2.780000 %\n",
      "     epoch 6, minibatch 100/100, test error of best model 2.800000 %\n",
      "training @ iter =  600\n",
      "epoch 7, minibatch 100/100, validation error 2.480000 %\n",
      "     epoch 7, minibatch 100/100, test error of best model 2.500000 %\n",
      "training @ iter =  700\n",
      "epoch 8, minibatch 100/100, validation error 2.290000 %\n",
      "     epoch 8, minibatch 100/100, test error of best model 2.220000 %\n",
      "training @ iter =  800\n",
      "epoch 9, minibatch 100/100, validation error 2.160000 %\n",
      "     epoch 9, minibatch 100/100, test error of best model 2.010000 %\n",
      "training @ iter =  900\n",
      "epoch 10, minibatch 100/100, validation error 1.970000 %\n",
      "     epoch 10, minibatch 100/100, test error of best model 1.880000 %\n",
      "training @ iter =  1000\n",
      "epoch 11, minibatch 100/100, validation error 1.880000 %\n",
      "     epoch 11, minibatch 100/100, test error of best model 1.790000 %\n",
      "training @ iter =  1100\n",
      "epoch 12, minibatch 100/100, validation error 1.790000 %\n",
      "     epoch 12, minibatch 100/100, test error of best model 1.660000 %\n",
      "training @ iter =  1200\n",
      "epoch 13, minibatch 100/100, validation error 1.760000 %\n",
      "     epoch 13, minibatch 100/100, test error of best model 1.580000 %\n",
      "training @ iter =  1300\n",
      "epoch 14, minibatch 100/100, validation error 1.710000 %\n",
      "     epoch 14, minibatch 100/100, test error of best model 1.550000 %\n",
      "training @ iter =  1400\n",
      "epoch 15, minibatch 100/100, validation error 1.680000 %\n",
      "     epoch 15, minibatch 100/100, test error of best model 1.500000 %\n",
      "training @ iter =  1500\n",
      "epoch 16, minibatch 100/100, validation error 1.620000 %\n",
      "     epoch 16, minibatch 100/100, test error of best model 1.440000 %\n",
      "training @ iter =  1600\n",
      "epoch 17, minibatch 100/100, validation error 1.590000 %\n",
      "     epoch 17, minibatch 100/100, test error of best model 1.410000 %\n",
      "training @ iter =  1700\n",
      "epoch 18, minibatch 100/100, validation error 1.560000 %\n",
      "     epoch 18, minibatch 100/100, test error of best model 1.410000 %\n",
      "training @ iter =  1800\n",
      "epoch 19, minibatch 100/100, validation error 1.530000 %\n",
      "     epoch 19, minibatch 100/100, test error of best model 1.380000 %\n",
      "training @ iter =  1900\n",
      "epoch 20, minibatch 100/100, validation error 1.520000 %\n",
      "     epoch 20, minibatch 100/100, test error of best model 1.330000 %\n",
      "training @ iter =  2000\n",
      "epoch 21, minibatch 100/100, validation error 1.490000 %\n",
      "     epoch 21, minibatch 100/100, test error of best model 1.270000 %\n",
      "training @ iter =  2100\n",
      "epoch 22, minibatch 100/100, validation error 1.460000 %\n",
      "     epoch 22, minibatch 100/100, test error of best model 1.270000 %\n",
      "training @ iter =  2200\n",
      "epoch 23, minibatch 100/100, validation error 1.430000 %\n",
      "     epoch 23, minibatch 100/100, test error of best model 1.240000 %\n",
      "training @ iter =  2300\n",
      "epoch 24, minibatch 100/100, validation error 1.410000 %\n",
      "     epoch 24, minibatch 100/100, test error of best model 1.230000 %\n",
      "training @ iter =  2400\n",
      "epoch 25, minibatch 100/100, validation error 1.380000 %\n",
      "     epoch 25, minibatch 100/100, test error of best model 1.190000 %\n",
      "training @ iter =  2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/DeepLearningTutorials/code/convolutional_mlp.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[0mevaluate_lenet5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/DeepLearningTutorials/code/convolutional_mlp.py\u001b[0m in \u001b[0;36mevaluate_lenet5\u001b[1;34m(learning_rate, n_epochs, dataset, nkerns, batch_size)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m'training @ iter = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalidation_frequency\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run convolutional_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano;import numpy as np;import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = RandomStreams(seed=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = rs.normal((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = rs.normal((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = T.dot(X + A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_A = theano.shared(value=np.zeros((10,10), dtype=theano.config.floatX),name='shared_A',borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_B = theano.shared(value=np.zeros((10,1), dtype=theano.config.floatX),name='shared_B',broadcastable=(False, True),\n",
    "                        borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = theano.function([], F, updates=[(shared_A,A), (shared_B, B)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.57980129],\n",
       "       [-2.21709898],\n",
       "       [-1.45155521],\n",
       "       [ 0.85739524],\n",
       "       [-1.48090466],\n",
       "       [ 0.60923798],\n",
       "       [-1.93954337],\n",
       "       [-3.13612358],\n",
       "       [-3.71339724],\n",
       "       [-3.56166751]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eq_test_left = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eq_test_right = np.dot(X + shared_A.get_value(), shared_B.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eq_test_left == eq_test_right).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
