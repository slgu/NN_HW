\documentclass[twoside,11pt]{homework}

\coursename{ECBM6040 NEURAL NETWORKS\&DEEP LEARNING (Spring 2015)} % DON'T CHANGE THIS

\studname{Shenlong Gu}    % YOUR NAME GOES HERE
\studmail{sg3301@columbia.edu}% YOUR UNI GOES HERE
\hwNo{1}                   % THE HOMEWORK NUMBER GOES HERE
\collab{}   % THE UNI'S OF STUDENTS YOU DISCUSSED WITH

% Uncomment the next line if you want to use \includegraphics.
%\usepackage{graphicx}

\begin{document}

\maketitle

\section*{Problem c}
1. We just apply the rule: $p_{y}(y) = p_{x}(x)$ * $|\frac{d_{x}}{d_{y}}|$ to the problem. \\
It is easy to calculate $\frac{d_{x}}{d_{y}}$ = -$\lambda * e^{-\lambda * y}$.
So when $\lambda$ $\ge$ 0,  \\
\begin{equation} 
p_{y}(y) = 
\left\{ 
\begin{array} 
    {r@{\quad:\quad}l} 
    \lambda * e^{-\lambda * y} & y > 0 \\ 
    0  &  otherwise
\end{array} 
\right. 
\end{equation}	
When $\lambda$ $\le$ 0, \\
\begin{equation} 
p_{y}(y) = 
\left\{ 
\begin{array} 
    {r@{\quad:\quad}l} 
    -\lambda * e^{-\lambda * y} & y < 0 \\ 
    0  &  otherwise
\end{array} 
\right. 
\end{equation}	
2. $p(x = x)$ = $\int_{0}^{1} 3*(x*y^{2} + x^{2} * y) d_{y}$ = $x$ + $\frac{3}{2} * x^{2}$. \\
In the same way $p(y = y)$ =  $y$ + $\frac{3}{2} * y^{2}$. \\
E(x) =  $\int_{0}^{1} \int_{0}^{1} 3x *(x*y^{2} + x^{2} * y) d_{x}d_{y}$ = $\frac{17}{24}$. \\
In the same way, E(y) =  $\frac{24}{17}$. \\
E(xy) = $\int_{0}^{1} \int_{0}^{1} 3xy *(x*y^{2} + x^{2} * y) d_{x}d_{y}$ = $\frac{1}{2}$ $\neq$ E(x) * E(y). \\
So x and y are not independent.
\section*{Problem d}
1. First we get the log maximum likelihood and ignore the const item as shown below:
P = $\sum_{i=0}^{m}$ -$\frac{1}{2}$ $(x_{i} - u)^{T} \sum^{-1} (x_{i} - u)$ - $\frac{m}{2}$ * ln($|\sum|$)
let's get the derivative for $u$ and let it to be 0: \\
$\sum_{i=0}^{m}$ -$\sum^{-1} (x_{i} - u)^{T}$ = 0 $\Longrightarrow$ $\sum_{i=0}^{m}$ $(x_{i} - u)$ = 0 $\Longrightarrow$ the estimator for $u$ is $u$ = $\frac{\sum_{i=0}^{m}x_{i}}{m}$  \\
Then let's get the derivative for $\sum$ and let it to be 0: \\
 $\sum_{i=0}^{m}$ $(x_{i} - u) * (x_{i} - u)^{T}$ - m * $\sum$ = 0 $\Longrightarrow$ the estimator for $\sum$ is $\sum$ = $\frac{\sum_{i=0}^{m} (x_{i} - u) * (x_{i} - u)^{T}}{m}$ \\
 2. 

\end{document} 
